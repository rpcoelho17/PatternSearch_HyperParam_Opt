{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Size Study w/ ExtraTreesRegressor with Cross_Validade:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Training & Validation Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T22:35:11.310569Z",
     "start_time": "2019-06-10T22:35:04.444704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitPoint:  100553\n",
      "Training Set shape (100553, 18)\n",
      "Validation Set shape (20405, 18)\n",
      " \n",
      " \n",
      "Train Data Type Descriptions:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100553 entries, 0 to 100552\n",
      "Data columns (total 18 columns):\n",
      "StoreID                 100553 non-null int32\n",
      "IsHoliday               100553 non-null int32\n",
      "IsOpen                  100553 non-null int32\n",
      "HasPromotions           100553 non-null int32\n",
      "StoreType               100553 non-null int8\n",
      "AssortmentType          100553 non-null int8\n",
      "NearestCompetitor       100553 non-null int32\n",
      "Region                  100553 non-null int32\n",
      "NumberOfSales           100553 non-null int32\n",
      "Region_AreaKM2          100553 non-null int32\n",
      "Region_GDP              100553 non-null int32\n",
      "Region_PopulationK      100553 non-null int32\n",
      "Year                    100553 non-null int32\n",
      "Month (number)          100553 non-null int32\n",
      "Week                    100553 non-null int32\n",
      "Day of year             100553 non-null int32\n",
      "Day of month            100553 non-null int32\n",
      "Day of week (number)    100553 non-null int32\n",
      "dtypes: int32(16), int8(2)\n",
      "memory usage: 7.1 MB\n",
      "None\n",
      " \n",
      " \n",
      "Feature Columns:\n",
      "Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n",
      "Win\n",
      "7\n",
      "3.6.7\n",
      "sklearn\n",
      "0.20.2\n"
     ]
    }
   ],
   "source": [
    "#Load Training and Validation sets:\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "trainBench = pd.read_csv(\"c:/Benchmarking/trainBench.csv\")\n",
    "#testBench = pd.read_csv(\"c:/Benchmarking/testBench.csv\")\n",
    "validBench = pd.read_csv(\"c:/Benchmarking/validBench.csv\")\n",
    "\n",
    "SplitPoint=len(trainBench.index) #SplitPoint = trainBench.shape[0] #trainBench.count(axis=0)\n",
    "print(\"SplitPoint: \",SplitPoint)\n",
    "\n",
    "df = pd.concat([trainBench,validBench],axis=0)\n",
    "del trainBench, validBench\n",
    "gc.collect()\n",
    "\n",
    "df = df.drop(\"ID\", axis=1)\n",
    "Int64columns = df.select_dtypes(['int64']).columns\n",
    "#Int64columns\n",
    "df[Int64columns] = df[Int64columns].astype(np.int32)\n",
    "#df['Date']=pd.to_datetime(dict(year=df['Year'], month=df['Month (number)'], day=df['Day of month']))\n",
    "#numerical enconde Assortment type & Store Type\n",
    "cat_columns = df.select_dtypes(['object']).columns\n",
    "df[cat_columns] = df[cat_columns].astype('category')\n",
    "#print(\"Categorical Columns:\")\n",
    "#print(df.select_dtypes(['category']).columns)\n",
    "#print(\" \")\n",
    "#print(\" \")\n",
    "df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "#print(\"Categorical Columns:\")\n",
    "#print(df.select_dtypes(['category']).columns)\n",
    "#print(\" \")\n",
    "#print(\" \")\n",
    "\n",
    "trainBench, validBench = df.iloc[:SplitPoint, :], df.iloc[SplitPoint:, :]\n",
    "print(\"Training Set shape\",trainBench.shape)\n",
    "print(\"Validation Set shape\",validBench.shape)\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Train Data Type Descriptions:\")\n",
    "TrainDataTypes=trainBench.dtypes\n",
    "#print(TrainDataTypes)\n",
    "print(trainBench.info())\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#print(validBench.info())\n",
    "\n",
    "# Split Features and Responses\n",
    "mask = trainBench.columns.difference(['NumberOfSales'])\n",
    "trainDataset_X = trainBench[mask]\n",
    "#print(\" \")\n",
    "#print(\" \")\n",
    "print(\"Feature Columns:\")\n",
    "print(mask)\n",
    "trainDataset_y = trainBench['NumberOfSales']\n",
    "#print(\"Head of Validation Data:\")\n",
    "#print(validBench.head(3))\n",
    "#print(\" \")\n",
    "#print(mask)\n",
    "validBench_X = validBench[mask]\n",
    "validBench_y = validBench['NumberOfSales']\n",
    "#CatCols=[trainBench.columns.get_loc(c) for c in trainBench.select_dtypes(['category']).columns if c in trainBench]\n",
    "del trainBench, validBench\n",
    "gc\n",
    "import platform\n",
    "import sys\n",
    "OpSys=platform.system()[:3]\n",
    "print(OpSys)\n",
    "OpSysVer=platform.release()\n",
    "print(OpSysVer)\n",
    "LangVer=sys.version[:5]\n",
    "print(LangVer)\n",
    "import sklearn\n",
    "Lib='sklearn'\n",
    "print(Lib)\n",
    "LibVer= sklearn.__version__\n",
    "print(LibVer)\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "workbook_name = 'C:\\\\Benchmarking\\\\AlgoPerf.xlsx'\n",
    "def xlsADD(row):\n",
    "    wb = load_workbook(workbook_name)\n",
    "    page = wb.active\n",
    "    page.append(row)\n",
    "    wb.save(filename=workbook_name) \n",
    "\n",
    "def InsertHeader():\n",
    "    Result=('OpSys','OpVer', \n",
    "            'Lang', \n",
    "            'LangVer', \n",
    "            'Lib', \n",
    "            'Lib.Ver', \n",
    "            'Algo',\n",
    "            'M_FitTime', \n",
    "            'XVR_FitTime',\n",
    "            'XVR_ScorTime',\n",
    "            'XV_Time',\n",
    "            'XV_EV',\n",
    "            'XV_MAE', \n",
    "            'XV_MSE', \n",
    "            'XV_RMSE', \n",
    "            'XV_R2',\n",
    "            'TS_PredTime',\n",
    "            'TS_EV',\n",
    "            'TS_MAE', \n",
    "            'TS_MSE', \n",
    "            'TS_RMSE', \n",
    "            'TS_R2',\n",
    "            'MeanEV',\n",
    "            'MdlParam', \n",
    "            'FeatImp',\n",
    "            'TdTypes',\n",
    "            'Comments')\n",
    "    #print(Result)\n",
    "    xlsADD(Result)\n",
    "    \n",
    "def InsertValues():\n",
    "    Result=(OpSys, \n",
    "            OpSysVer, \n",
    "            'Python', \n",
    "            LangVer, \n",
    "            Lib, \n",
    "            LibVer,\n",
    "            Algo,\n",
    "            M_FitTime, \n",
    "            XVR_FT,\n",
    "            ST,\n",
    "            XValidTime,\n",
    "            EV,\n",
    "            MAE, \n",
    "            MSE, \n",
    "            RMSE, \n",
    "            R2,\n",
    "            PredTime,\n",
    "            EVv,\n",
    "            MAEv, \n",
    "            MSEv, \n",
    "            RMSEv, \n",
    "            R2v,\n",
    "            EVtot.mean(),\n",
    "            str(Params), \n",
    "            str(d),\n",
    "            str(TrainDataTypes),\n",
    "            Comments)\n",
    "    #print(Result)\n",
    "    xlsADD(Result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:28:19.530409Z",
     "start_time": "2019-06-10T23:28:19.484407Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Cross Validate and Score\n",
    "params={}\n",
    "def CrossEval(SplitPercent=20,MdlParams={}, verbose=False):\n",
    "    #**************Insert comments about this run here:\n",
    "    global Comments\n",
    "    #Comments='n_estimators=250, max_features=n_features-15, max_depth = 15, '+ str(SplitPercent)+'% of the training data'\n",
    "    global Algo\n",
    "    Algo='ExtraTreesRegressor'\n",
    "    Nrows,Ncols=trainDataset_X.shape\n",
    "    SplitPoint=int(Nrows*(SplitPercent/100))\n",
    "    X, y = trainDataset_X.iloc[:SplitPoint, :], trainDataset_y.iloc[:SplitPoint]\n",
    "    #if verbose: \n",
    "    print(\"Training data set shape:\",X.shape)\n",
    "    start=time.time()\n",
    "    forest = ExtraTreesRegressor(n_estimators=240, \n",
    "                                 max_features = int(X.columns.size - 15),\n",
    "                                 max_depth = 16,\n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=0)\n",
    "    if MdlParams != {}:\n",
    "        forest.set_params(**MdlParams)\n",
    "    \n",
    "    forest.fit(X, y)\n",
    "    global M_FitTime, XValidTime, PredTime\n",
    "    M_FitTime = time.time() - start\n",
    "    if verbose:print(\"Measured Fit Time: \", M_FitTime)\n",
    "\n",
    "    UseTScv=True\n",
    "    if UseTScv:\n",
    "        from sklearn.model_selection import TimeSeriesSplit\n",
    "        if verbose:print(\"Using Time Series Cross Validation\")\n",
    "        start=time.time()\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=tscv, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )        \n",
    "    else:\n",
    "        from sklearn.model_selection import KFold\n",
    "        if verbose:print(\"Using KFold Cross Validation\")\n",
    "        start=time.time()\n",
    "        kfolds = KFold(n_splits=5,shuffle=False,random_state=0)\n",
    "        scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=kfolds, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )\n",
    "\n",
    "    XValidTime = time.time() - start\n",
    "\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Model Parameters: \")\n",
    "    global Params\n",
    "    Params=forest.get_params(deep=True)\n",
    "    if verbose:print(Params)\n",
    "    if verbose:print(\" \"); \n",
    "    global EV, MAE, MSE, RMSE, R2,XVR_FT, ST \n",
    "    if verbose:print(\"Cross Validation Performance: \")\n",
    "    #if verbose:\n",
    "    print(\"Cross Validation Time: %0.6f\" % (XValidTime))\n",
    "    EV=scores['test_explained_variance'].mean()\n",
    "    if verbose:print(scores['test_explained_variance'])\n",
    "    if verbose:print(\"EV: %0.6f\" % (EV))\n",
    "    #MAE is less sensitive to outliers, The contant value that minimizes the MAE is the median of the target values\n",
    "    if verbose:print(-1*scores['test_neg_mean_absolute_error'])\n",
    "    MAE=-1*scores['test_neg_mean_absolute_error'].mean()\n",
    "    if verbose:print(\"MAE: %0.6f\" % (MAE))\n",
    "    #MAE considers outliers, The contant value that minimizes the MSE is the mean of the target values\n",
    "    #If you think your outliers are erros in the data use MAE, if you think the outliers are true datapoints use MSE.\n",
    "    #It is easier to optmize MSE than RMSE because RMSE requires an adjustable learning rate.\n",
    "    if verbose:print(-1*scores['test_neg_mean_squared_error'])\n",
    "    MSE=-1*scores['test_neg_mean_squared_error'].mean()\n",
    "    if verbose:print(\"MSE: %0.6f\" % (MSE))\n",
    "    if verbose:print(np.sqrt(-1*scores['test_neg_mean_squared_error']))\n",
    "    RMSE=np.sqrt(-1*scores['test_neg_mean_squared_error'].mean())\n",
    "    if verbose:print(\"RMSE: %0.6f\" % (RMSE))\n",
    "    #Optimizing R2 and optimizing for MSE is the same, since R2 = 1-(MSE/Constant)\n",
    "    if verbose:print(\"XV R2 Actuals:\",scores['test_r2'])\n",
    "    R2=scores['test_r2'].mean()\n",
    "    if verbose:print(\"Cross Validation R2: %0.6f\" % (R2))\n",
    "    if verbose:print(\"XVR_fit_time Actuals: \", (scores['fit_time']))\n",
    "    XVR_FT=scores['fit_time'].mean()\n",
    "    if verbose:print(\"XVR_fit_time: %0.6f\" % (XVR_FT))\n",
    "    if verbose:print(\"score_time Actuals: \", (scores['score_time']))      \n",
    "    ST=scores['score_time'].mean()\n",
    "    if verbose:print(\"score_time: %0.6f\" % (ST))\n",
    "\n",
    "    Comments=str(Params)\n",
    "    \n",
    "    # Score Validation Set: \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import explained_variance_score\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    start=time.time()\n",
    "    y_pred=forest.predict(validBench_X)\n",
    "    PredTime = time.time() - start\n",
    "\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\" \")\n",
    "    global EVv, MAEv, MSEv, RMSEv, R2v, EVtot\n",
    "    if verbose:print(\"Prediction Time: \", PredTime)\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Validation data set shape:\",validBench_X.shape)\n",
    "    EVv=explained_variance_score(validBench_y, y_pred)\n",
    "    if verbose:print(\"Validation Set Explained Variance (EV): %0.2f\" % (EVv))\n",
    "    #MAE is less sensitive to outliers, The constant value that minimizes the MAE is the median of the target values\n",
    "    MAEv=mean_absolute_error(validBench_y, y_pred)\n",
    "    if verbose:print(\"MAE: %0.6f\" % (MAEv))\n",
    "    #MAE considers outliers, The contant value that minimizes the MSE is the mean of the target values\n",
    "    #If you think your outliers are erros in the data use MAE, if you think the outliers are true datapoints use MSE.\n",
    "    #It is easier to optmize MSE than RMSE because RMSE requires an adjustable learning rate.\n",
    "    MSEv=mean_squared_error(validBench_y, y_pred)\n",
    "    if verbose:print(\"MSE: %0.6f\" % (MSEv))\n",
    "    RMSEv=np.sqrt(MSEv)\n",
    "    if verbose:print(\"RMSE: %0.6f\" % (RMSEv))\n",
    "    #Optimizing R2 and optimizing for MSE is the same, since R2 = 1-(MSE/Constant)\n",
    "    R2v=r2_score(validBench_y, y_pred)\n",
    "    if verbose:print(\"Validation Set R2: %0.6f\" % (R2v))\n",
    "    EVtot=scores['test_explained_variance'].copy()\n",
    "    EVtot = np.append(EVtot,EVv)\n",
    "    EVtotMean=EVtot.mean()\n",
    "    if verbose:print(\"Total Mean EV: \",EVtot,EVtotMean)\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Feature Importances:\")\n",
    "    global d\n",
    "    d=[]\n",
    "    \n",
    "    for f in range(X.shape[1]):\n",
    "        if verbose:print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "        d.append({\"%d. feat: %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]])})\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Validation Set EV, XVal EV, Mean EV: \",EVv, EV, EVtotMean)\n",
    "    #InsertHeader()\n",
    "    #InsertValues()\n",
    "    return EVv, EV, EVtotMean, R2v, R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:20:28.098539Z",
     "start_time": "2019-06-10T23:20:28.053536Z"
    }
   },
   "outputs": [],
   "source": [
    "#This version of CrossEval takes the Model as a parameter (Mdl)\n",
    "#Cross Validate and Score\n",
    "params={}\n",
    "def CrossEval2(SplitPercent=20,Mdl=ExtraTreesRegressor,MdlParams={}, verbose=False):\n",
    "    #**************Insert comments about this run here:\n",
    "    global Comments\n",
    "    #Comments='n_estimators=250, max_features=n_features-15, max_depth = 15, '+ str(SplitPercent)+'% of the training data'\n",
    "    global Algo\n",
    "    Algo=Mdl.__name__\n",
    "    if verbose: print(\"Current Model: \", Algo)\n",
    "    Nrows,Ncols=trainDataset_X.shape\n",
    "    SplitPoint=int(Nrows*(SplitPercent/100))\n",
    "    X, y = trainDataset_X.iloc[:SplitPoint, :], trainDataset_y.iloc[:SplitPoint]\n",
    "    #if verbose: \n",
    "    print(\"Training data set shape:\",X.shape)\n",
    "    start=time.time()\n",
    "    \n",
    "    forest = Mdl()\n",
    "    \n",
    "    if MdlParams != {}:\n",
    "        forest.set_params(**MdlParams)\n",
    "    else:\n",
    "        forest.set_params(n_estimators=240, \n",
    "                          max_features = int(X.columns.size - 15),\n",
    "                          max_depth = 16,\n",
    "                          n_jobs=-1, \n",
    "                          random_state=0)\n",
    "    \n",
    "    forest.fit(X, y)\n",
    "    global M_FitTime, XValidTime, PredTime\n",
    "    M_FitTime = time.time() - start\n",
    "    if verbose:print(\"Measured Fit Time: \", M_FitTime)\n",
    "\n",
    "    UseTScv=True\n",
    "    if UseTScv:\n",
    "        from sklearn.model_selection import TimeSeriesSplit\n",
    "        if verbose:print(\"Using Time Series Cross Validation\")\n",
    "        start=time.time()\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=tscv, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )        \n",
    "    else:\n",
    "        from sklearn.model_selection import KFold\n",
    "        if verbose:print(\"Using KFold Cross Validation\")\n",
    "        start=time.time()\n",
    "        kfolds = KFold(n_splits=5,shuffle=False,random_state=0)\n",
    "        scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=kfolds, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )\n",
    "\n",
    "    XValidTime = time.time() - start\n",
    "\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Model Parameters: \")\n",
    "    global Params\n",
    "    Params=forest.get_params(deep=True)\n",
    "    if verbose:print(Params)\n",
    "    if verbose:print(\" \"); \n",
    "    global EV, MAE, MSE, RMSE, R2,XVR_FT, ST \n",
    "    if verbose:print(\"Cross Validation Performance: \")\n",
    "    #if verbose:\n",
    "    print(\"Cross Validation Time: %0.6f\" % (XValidTime))\n",
    "    EV=scores['test_explained_variance'].mean()\n",
    "    if verbose:print(scores['test_explained_variance'])\n",
    "    if verbose:print(\"EV: %0.6f\" % (EV))\n",
    "    #MAE is less sensitive to outliers, The contant value that minimizes the MAE is the median of the target values\n",
    "    if verbose:print(-1*scores['test_neg_mean_absolute_error'])\n",
    "    MAE=-1*scores['test_neg_mean_absolute_error'].mean()\n",
    "    if verbose:print(\"MAE: %0.6f\" % (MAE))\n",
    "    #MAE considers outliers, The contant value that minimizes the MSE is the mean of the target values\n",
    "    #If you think your outliers are erros in the data use MAE, if you think the outliers are true datapoints use MSE.\n",
    "    #It is easier to optmize MSE than RMSE because RMSE requires an adjustable learning rate.\n",
    "    if verbose:print(-1*scores['test_neg_mean_squared_error'])\n",
    "    MSE=-1*scores['test_neg_mean_squared_error'].mean()\n",
    "    if verbose:print(\"MSE: %0.6f\" % (MSE))\n",
    "    if verbose:print(np.sqrt(-1*scores['test_neg_mean_squared_error']))\n",
    "    RMSE=np.sqrt(-1*scores['test_neg_mean_squared_error'].mean())\n",
    "    if verbose:print(\"RMSE: %0.6f\" % (RMSE))\n",
    "    #Optimizing R2 and optimizing for MSE is the same, since R2 = 1-(MSE/Constant)\n",
    "    if verbose:print(\"XV R2 Actuals:\",scores['test_r2'])\n",
    "    R2=scores['test_r2'].mean()\n",
    "    if verbose:print(\"Cross Validation R2: %0.6f\" % (R2))\n",
    "    if verbose:print(\"XVR_fit_time Actuals: \", (scores['fit_time']))\n",
    "    XVR_FT=scores['fit_time'].mean()\n",
    "    if verbose:print(\"XVR_fit_time: %0.6f\" % (XVR_FT))\n",
    "    if verbose:print(\"score_time Actuals: \", (scores['score_time']))      \n",
    "    ST=scores['score_time'].mean()\n",
    "    if verbose:print(\"score_time: %0.6f\" % (ST))\n",
    "\n",
    "    Comments=str(Params)\n",
    "    \n",
    "    # Score Validation Set: \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import explained_variance_score\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    start=time.time()\n",
    "    y_pred=forest.predict(validBench_X)\n",
    "    PredTime = time.time() - start\n",
    "\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\" \")\n",
    "    global EVv, MAEv, MSEv, RMSEv, R2v, EVtot\n",
    "    if verbose:print(\"Prediction Time: \", PredTime)\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Validation data set shape:\",validBench_X.shape)\n",
    "    EVv=explained_variance_score(validBench_y, y_pred)\n",
    "    if verbose:print(\"Validation Set Explained Variance (EV): %0.2f\" % (EVv))\n",
    "    #MAE is less sensitive to outliers, The constant value that minimizes the MAE is the median of the target values\n",
    "    MAEv=mean_absolute_error(validBench_y, y_pred)\n",
    "    if verbose:print(\"MAE: %0.6f\" % (MAEv))\n",
    "    #MAE considers outliers, The contant value that minimizes the MSE is the mean of the target values\n",
    "    #If you think your outliers are erros in the data use MAE, if you think the outliers are true datapoints use MSE.\n",
    "    #It is easier to optmize MSE than RMSE because RMSE requires an adjustable learning rate.\n",
    "    MSEv=mean_squared_error(validBench_y, y_pred)\n",
    "    if verbose:print(\"MSE: %0.6f\" % (MSEv))\n",
    "    RMSEv=np.sqrt(MSEv)\n",
    "    if verbose:print(\"RMSE: %0.6f\" % (RMSEv))\n",
    "    #Optimizing R2 and optimizing for MSE is the same, since R2 = 1-(MSE/Constant)\n",
    "    R2v=r2_score(validBench_y, y_pred)\n",
    "    if verbose:print(\"Validation Set R2: %0.6f\" % (R2v))\n",
    "    EVtot=scores['test_explained_variance'].copy()\n",
    "    EVtot = np.append(EVtot,EVv)\n",
    "    EVtotMean=EVtot.mean()\n",
    "    if verbose:print(\"Total Mean EV: \",EVtot,EVtotMean)\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Feature Importances:\")\n",
    "    global d\n",
    "    d=[]\n",
    "    \n",
    "    for f in range(X.shape[1]):\n",
    "        if verbose:print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "        d.append({\"%d. feat: %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]])})\n",
    "    if verbose:print(\" \")\n",
    "    if verbose:print(\"Validation Set EV, XVal EV, Mean EV: \",EVv, EV, EVtotMean)\n",
    "    #InsertHeader()\n",
    "    #InsertValues()\n",
    "    return EVv, EV, EVtotMean,R2v,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:21:04.334835Z",
     "start_time": "2019-06-10T23:20:31.407223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model:  ExtraTreesRegressor\n",
      "Training data set shape: (100553, 17)\n",
      "Measured Fit Time:  3.005171537399292\n",
      "Using Time Series Cross Validation\n",
      " \n",
      "Model Parameters: \n",
      "{'bootstrap': False, 'criterion': 'mse', 'max_depth': 16, 'max_features': 2, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 240, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 29.462414\n",
      "[0.6893979  0.55408824 0.64868223 0.67215276 0.39283517]\n",
      "EV: 0.591431\n",
      "[ 965.77104548 1290.12103312 1130.37150079 1032.344633   1251.99564222]\n",
      "MAE: 1134.120771\n",
      "[2031006.19284856 3981787.24555979 2449460.21873086 2362433.8414521\n",
      " 6041839.27572217]\n",
      "MSE: 3373305.354863\n",
      "[1425.1337456  1995.44161668 1565.07514795 1537.02109337 2458.01531234]\n",
      "RMSE: 1836.656025\n",
      "XV R2 Actuals: [0.66915499 0.55369165 0.64824639 0.67212614 0.39255823]\n",
      "Cross Validation R2: 0.587155\n",
      "XVR_fit_time Actuals:  [3.62713313 2.20512629 2.7980938  3.16667175 3.96119571]\n",
      "XVR_fit_time: 3.151644\n",
      "score_time Actuals:  [0.83104229 0.82504702 0.82703376 0.83152747 0.83304501]\n",
      "score_time: 0.829539\n",
      " \n",
      " \n",
      "Prediction Time:  0.20701217651367188\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.68\n",
      "MAE: 1057.398489\n",
      "MSE: 1995088.740405\n",
      "RMSE: 1412.476103\n",
      "Validation Set R2: 0.667064\n",
      "Total Mean EV:  [0.6893979  0.55408824 0.64868223 0.67215276 0.39283517 0.68034527] 0.6062502600317962\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.365634)\n",
      "2. feature 4 HasPromotions (0.149547)\n",
      "3. feature 2 Day of week (number) (0.104564)\n",
      "4. feature 13 StoreID (0.049110)\n",
      "5. feature 11 Region_GDP (0.043111)\n",
      "6. feature 8 NearestCompetitor (0.042815)\n",
      "7. feature 14 StoreType (0.041804)\n",
      "8. feature 5 IsHoliday (0.039832)\n",
      "9. feature 0 AssortmentType (0.036843)\n",
      "10. feature 10 Region_AreaKM2 (0.026902)\n",
      "11. feature 12 Region_PopulationK (0.023678)\n",
      "12. feature 9 Region (0.020062)\n",
      "13. feature 3 Day of year (0.015112)\n",
      "14. feature 1 Day of month (0.014028)\n",
      "15. feature 15 Week (0.012853)\n",
      "16. feature 7 Month (number) (0.010592)\n",
      "17. feature 16 Year (0.003513)\n",
      " \n",
      "Validation Set EV, XVal EV, Mean EV:  0.6803452671668492 0.5914312586047856 0.6062502600317962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6803452671668492,\n",
       " 0.5914312586047856,\n",
       " 0.6062502600317962,\n",
       " 0.667063798808587,\n",
       " 0.5871554790932797)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "MdlParams={}\n",
    "Mdl=ExtraTreesRegressor\n",
    "CrossEval2(100, Mdl=Mdl, MdlParams=MdlParams,verbose=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Study: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:20:08.643852Z",
     "start_time": "2019-04-26T03:16:39.675802Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set shape: (20110, 17)\n",
      "Measured Fit Time:  0.8934476375579834\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.826221\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.18125725 1.64521885 2.16161036 2.51963973 3.08020592]\n",
      "XVR_fit_time: 2.117586\n",
      "score_time Actuals:  [0.87560153 0.87660193 0.85982919 0.8892014  0.87360144]\n",
      "score_time: 0.874967\n",
      " \n",
      " \n",
      "Prediction Time:  0.2184004783630371\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.67\n",
      "MAE: 1021.464769\n",
      "MSE: 1963549.971611\n",
      "RMSE: 1401.267273\n",
      "Validation Set R2: 0.672327\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.67250382] 0.6035212700015493\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.393535)\n",
      "2. feature 4 HasPromotions (0.184543)\n",
      "3. feature 2 Day of week (number) (0.114266)\n",
      "4. feature 13 StoreID (0.044849)\n",
      "5. feature 8 NearestCompetitor (0.044226)\n",
      "6. feature 5 IsHoliday (0.038938)\n",
      "7. feature 12 Region_PopulationK (0.020104)\n",
      "8. feature 3 Day of year (0.019854)\n",
      "9. feature 9 Region (0.019032)\n",
      "10. feature 1 Day of month (0.018635)\n",
      "11. feature 11 Region_GDP (0.017179)\n",
      "12. feature 14 StoreType (0.017155)\n",
      "13. feature 0 AssortmentType (0.016919)\n",
      "14. feature 15 Week (0.016285)\n",
      "15. feature 10 Region_AreaKM2 (0.016111)\n",
      "16. feature 7 Month (number) (0.012802)\n",
      "17. feature 16 Year (0.005568)\n",
      "Training data set shape: (30165, 17)\n",
      "Measured Fit Time:  1.0424044132232666\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 24.015146\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.21560383 1.6720612  2.07441568 2.61320496 3.0420053 ]\n",
      "XVR_fit_time: 2.123458\n",
      "score_time Actuals:  [0.89520192 0.83681059 0.87360144 0.87360168 0.88920164]\n",
      "score_time: 0.873683\n",
      " \n",
      " \n",
      "Prediction Time:  0.2184004783630371\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.66\n",
      "MAE: 1133.752583\n",
      "MSE: 2131660.738144\n",
      "RMSE: 1460.020801\n",
      "Validation Set R2: 0.644273\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.65551759] 0.6006902317740543\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.413621)\n",
      "2. feature 4 HasPromotions (0.185221)\n",
      "3. feature 2 Day of week (number) (0.117410)\n",
      "4. feature 13 StoreID (0.044955)\n",
      "5. feature 8 NearestCompetitor (0.043371)\n",
      "6. feature 5 IsHoliday (0.039386)\n",
      "7. feature 9 Region (0.019020)\n",
      "8. feature 3 Day of year (0.018731)\n",
      "9. feature 1 Day of month (0.016567)\n",
      "10. feature 12 Region_PopulationK (0.015893)\n",
      "11. feature 15 Week (0.015257)\n",
      "12. feature 11 Region_GDP (0.014645)\n",
      "13. feature 10 Region_AreaKM2 (0.014323)\n",
      "14. feature 14 StoreType (0.013385)\n",
      "15. feature 0 AssortmentType (0.011752)\n",
      "16. feature 7 Month (number) (0.011399)\n",
      "17. feature 16 Year (0.005063)\n",
      "Training data set shape: (40221, 17)\n",
      "Measured Fit Time:  1.284008502960205\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.860477\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.15200973 1.65840483 2.06240654 2.66062164 3.01000786]\n",
      "XVR_fit_time: 2.108690\n",
      "score_time Actuals:  [0.87860179 0.8922019  0.89520168 0.8766017  0.87560177]\n",
      "score_time: 0.883642\n",
      " \n",
      " \n",
      "Prediction Time:  0.3238029479980469\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.65\n",
      "MAE: 1149.250023\n",
      "MSE: 2334718.467287\n",
      "RMSE: 1527.978556\n",
      "Validation Set R2: 0.610387\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.64582835] 0.5990753578470595\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.400620)\n",
      "2. feature 4 HasPromotions (0.171990)\n",
      "3. feature 2 Day of week (number) (0.118357)\n",
      "4. feature 13 StoreID (0.057739)\n",
      "5. feature 8 NearestCompetitor (0.050280)\n",
      "6. feature 5 IsHoliday (0.040483)\n",
      "7. feature 0 AssortmentType (0.019354)\n",
      "8. feature 3 Day of year (0.018149)\n",
      "9. feature 9 Region (0.018091)\n",
      "10. feature 10 Region_AreaKM2 (0.015366)\n",
      "11. feature 1 Day of month (0.015310)\n",
      "12. feature 15 Week (0.014842)\n",
      "13. feature 14 StoreType (0.014711)\n",
      "14. feature 12 Region_PopulationK (0.014115)\n",
      "15. feature 11 Region_GDP (0.012471)\n",
      "16. feature 7 Month (number) (0.012254)\n",
      "17. feature 16 Year (0.005869)\n",
      "Training data set shape: (50276, 17)\n",
      "Measured Fit Time:  1.4932060241699219\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.844252\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.10820532 1.66200423 2.12540555 2.60520482 3.02640533]\n",
      "XVR_fit_time: 2.105445\n",
      "score_time Actuals:  [0.87360168 0.89320183 0.88920164 0.8736012  0.89320159]\n",
      "score_time: 0.884562\n",
      " \n",
      " \n",
      "Prediction Time:  0.218400239944458\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.62\n",
      "MAE: 1186.198887\n",
      "MSE: 2380180.163868\n",
      "RMSE: 1542.783252\n",
      "Validation Set R2: 0.602801\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.62124636] 0.594978360849488\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.392009)\n",
      "2. feature 4 HasPromotions (0.166869)\n",
      "3. feature 2 Day of week (number) (0.117591)\n",
      "4. feature 13 StoreID (0.057730)\n",
      "5. feature 8 NearestCompetitor (0.056800)\n",
      "6. feature 5 IsHoliday (0.041692)\n",
      "7. feature 0 AssortmentType (0.021644)\n",
      "8. feature 14 StoreType (0.019613)\n",
      "9. feature 10 Region_AreaKM2 (0.018346)\n",
      "10. feature 12 Region_PopulationK (0.018216)\n",
      "11. feature 9 Region (0.017458)\n",
      "12. feature 3 Day of year (0.016136)\n",
      "13. feature 11 Region_GDP (0.015023)\n",
      "14. feature 1 Day of month (0.013859)\n",
      "15. feature 15 Week (0.012944)\n",
      "16. feature 7 Month (number) (0.010293)\n",
      "17. feature 16 Year (0.003776)\n",
      "Training data set shape: (60331, 17)\n",
      "Measured Fit Time:  1.6936051845550537\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.888854\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.15120792 1.60680294 2.10800385 2.57780623 3.00560689]\n",
      "XVR_fit_time: 2.089886\n",
      "score_time Actuals:  [0.89320159 0.87560177 0.87560153 0.87360168 0.8736012 ]\n",
      "score_time: 0.878322\n",
      " \n",
      " \n",
      "Prediction Time:  0.218400239944458\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.63\n",
      "MAE: 1149.650829\n",
      "MSE: 2278250.830947\n",
      "RMSE: 1509.387568\n",
      "Validation Set R2: 0.619810\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.62875679] 0.5962300986385579\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.412960)\n",
      "2. feature 4 HasPromotions (0.168109)\n",
      "3. feature 2 Day of week (number) (0.111870)\n",
      "4. feature 8 NearestCompetitor (0.050135)\n",
      "5. feature 13 StoreID (0.046933)\n",
      "6. feature 5 IsHoliday (0.039631)\n",
      "7. feature 0 AssortmentType (0.022779)\n",
      "8. feature 11 Region_GDP (0.019439)\n",
      "9. feature 14 StoreType (0.019349)\n",
      "10. feature 12 Region_PopulationK (0.019143)\n",
      "11. feature 10 Region_AreaKM2 (0.017554)\n",
      "12. feature 3 Day of year (0.015476)\n",
      "13. feature 9 Region (0.015404)\n",
      "14. feature 1 Day of month (0.013976)\n",
      "15. feature 15 Week (0.012752)\n",
      "16. feature 7 Month (number) (0.010479)\n",
      "17. feature 16 Year (0.004011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set shape: (70387, 17)\n",
      "Measured Fit Time:  1.912212610244751\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.698446\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.16980362 1.57860303 2.10600376 2.49700451 3.02880645]\n",
      "XVR_fit_time: 2.076044\n",
      "score_time Actuals:  [0.87360168 0.8892014  0.8766017  0.89420176 0.87360168]\n",
      "score_time: 0.881442\n",
      " \n",
      " \n",
      "Prediction Time:  0.2184004783630371\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.62\n",
      "MAE: 1132.892700\n",
      "MSE: 2329374.467224\n",
      "RMSE: 1526.228838\n",
      "Validation Set R2: 0.611279\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.6192922 ] 0.5946526673653694\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.415181)\n",
      "2. feature 4 HasPromotions (0.171836)\n",
      "3. feature 2 Day of week (number) (0.115340)\n",
      "4. feature 8 NearestCompetitor (0.044115)\n",
      "5. feature 13 StoreID (0.042577)\n",
      "6. feature 5 IsHoliday (0.042488)\n",
      "7. feature 0 AssortmentType (0.029254)\n",
      "8. feature 12 Region_PopulationK (0.018064)\n",
      "9. feature 11 Region_GDP (0.017565)\n",
      "10. feature 14 StoreType (0.017121)\n",
      "11. feature 10 Region_AreaKM2 (0.016628)\n",
      "12. feature 3 Day of year (0.015325)\n",
      "13. feature 9 Region (0.014041)\n",
      "14. feature 1 Day of month (0.013621)\n",
      "15. feature 15 Week (0.012844)\n",
      "16. feature 7 Month (number) (0.010386)\n",
      "17. feature 16 Year (0.003612)\n",
      "Training data set shape: (80442, 17)\n",
      "Measured Fit Time:  2.2266056537628174\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.979246\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.26740408 1.62240291 2.10800362 2.62180448 3.05760527]\n",
      "XVR_fit_time: 2.135444\n",
      "score_time Actuals:  [0.87660146 0.87560129 0.87560177 0.87660193 0.87360168]\n",
      "score_time: 0.875602\n",
      " \n",
      " \n",
      "Prediction Time:  0.23400044441223145\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.64\n",
      "MAE: 1140.692240\n",
      "MSE: 2349348.979000\n",
      "RMSE: 1532.758617\n",
      "Validation Set R2: 0.607946\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.63544903] 0.5973454717154992\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.405038)\n",
      "2. feature 4 HasPromotions (0.171722)\n",
      "3. feature 2 Day of week (number) (0.116403)\n",
      "4. feature 5 IsHoliday (0.045028)\n",
      "5. feature 13 StoreID (0.042028)\n",
      "6. feature 8 NearestCompetitor (0.040620)\n",
      "7. feature 0 AssortmentType (0.032246)\n",
      "8. feature 14 StoreType (0.021267)\n",
      "9. feature 11 Region_GDP (0.019703)\n",
      "10. feature 10 Region_AreaKM2 (0.017813)\n",
      "11. feature 12 Region_PopulationK (0.017374)\n",
      "12. feature 9 Region (0.016238)\n",
      "13. feature 3 Day of year (0.014885)\n",
      "14. feature 1 Day of month (0.013727)\n",
      "15. feature 15 Week (0.012273)\n",
      "16. feature 7 Month (number) (0.010133)\n",
      "17. feature 16 Year (0.003501)\n",
      "Training data set shape: (90497, 17)\n",
      "Measured Fit Time:  2.4332163333892822\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 23.892272\n",
      "[0.68329983 0.55466659 0.65183528 0.66779217 0.39102993]\n",
      "EV: 0.589725\n",
      "[ 976.44519848 1292.50419848 1133.46605205 1044.31633422 1269.88681822]\n",
      "MAE: 1143.323720\n",
      "[2070151.61218798 3975607.97450234 2425820.47504332 2393693.14476846\n",
      " 6059182.7266187 ]\n",
      "MSE: 3384891.186624\n",
      "[1438.80214491 1993.89266875 1557.50456662 1547.15647068 2461.54072211]\n",
      "RMSE: 1839.807378\n",
      "XV R2 Actuals: [0.66277831 0.55438427 0.65164117 0.66778777 0.39081453]\n",
      "Cross Validation R2: 0.585481\n",
      "XVR_fit_time Actuals:  [1.14081073 1.60680294 2.10800385 2.57921171 3.11420774]\n",
      "XVR_fit_time: 2.109807\n",
      "score_time Actuals:  [0.88020992 0.88920164 0.89020181 0.87360168 0.88920164]\n",
      "score_time: 0.884483\n",
      " \n",
      " \n",
      "Prediction Time:  0.218400239944458\n",
      " \n",
      "Validation data set shape: (20405, 17)\n",
      "Validation Set Explained Variance (EV): 0.68\n",
      "MAE: 1118.532198\n",
      "MSE: 2114550.408269\n",
      "RMSE: 1454.149376\n",
      "Validation Set R2: 0.647128\n",
      "Total Mean EV:  [0.68329983 0.55466659 0.65183528 0.66779217 0.39102993 0.67901694] 0.6046067896890618\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.371401)\n",
      "2. feature 4 HasPromotions (0.153958)\n",
      "3. feature 2 Day of week (number) (0.098718)\n",
      "4. feature 13 StoreID (0.048849)\n",
      "5. feature 11 Region_GDP (0.047933)\n",
      "6. feature 14 StoreType (0.042108)\n",
      "7. feature 8 NearestCompetitor (0.041565)\n",
      "8. feature 0 AssortmentType (0.040047)\n",
      "9. feature 5 IsHoliday (0.038906)\n",
      "10. feature 10 Region_AreaKM2 (0.025018)\n",
      "11. feature 12 Region_PopulationK (0.021944)\n",
      "12. feature 9 Region (0.019908)\n",
      "13. feature 3 Day of year (0.013818)\n",
      "14. feature 1 Day of month (0.012168)\n",
      "15. feature 15 Week (0.011183)\n",
      "16. feature 7 Month (number) (0.009470)\n",
      "17. feature 16 Year (0.003006)\n"
     ]
    }
   ],
   "source": [
    "SampleSizes = [20, 30, 40, 50, 60, 70, 80, 90] \n",
    "for i in SampleSizes:\n",
    "    CrossEval(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Search Hooke-Jeeves Method:\n",
    "## References:\n",
    "https://www.mathworks.com/videos/global-optimization-toolbox-overview-73470.html\n",
    "\n",
    "https://www.youtube.com/watch?v=b-ob1sfXOTk&t=1823s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:28:42.728704Z",
     "start_time": "2019-06-10T23:28:42.710703Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dimension():\n",
    "    def __init__(self, value):\n",
    "        #If value is a Tuple, divide the interval into \"length\" equaly spaced intervals:\n",
    "        if isinstance(value,tuple):\n",
    "           lower=value[0];upper=value[1];length=value[2]\n",
    "           value=[lower + x*(upper-lower)/(length-1) for x in range(length)]\n",
    "        self.value=value\n",
    "        self.value.sort()\n",
    "        self.min=self.value[0]\n",
    "        self.max=self.value[-1]\n",
    "        self.midptidx=int((len(self.value)/2)-0.5)\n",
    "        self.midpoint=self.value[self.midptidx]\n",
    "        self.Delta=(len(value)-1)-self.midptidx\n",
    "        self.BestValue=self.midpoint\n",
    "        self.CurrIndex=self.midptidx\n",
    "        self.BestIndex=self.midptidx\n",
    "\n",
    "# Space={'n_estimators':Dimension([230,240,250]),\n",
    "#        'max_features':Dimension([2,3]),\n",
    "#        'max_depth':Dimension([16,17,30])}\n",
    "\n",
    "Space={'n_estimators':Dimension([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260]),\n",
    "        'max_features':Dimension([2,3,4]),\n",
    "        'max_depth':Dimension([5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17])}\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Search Result:\n",
    "Do not use the run below to compare with Baysian opt, and Random search. It uses a custom metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:35:52.926608Z",
     "start_time": "2019-06-10T23:28:52.139215Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 1 6\n",
      " \n",
      " \n",
      "{'n_estimators': 130, 'max_features': 3, 'max_depth': 11}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.019557\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1 {'n_estimators': 260, 'max_features': 3, 'max_depth': 11}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 17.488428\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "-1 {'n_estimators': 10, 'max_features': 3, 'max_depth': 11}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 4.982781\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "1 {'n_estimators': 130, 'max_features': 4, 'max_depth': 11}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.952114\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "-1 {'n_estimators': 130, 'max_features': 2, 'max_depth': 11}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.173531\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "1 {'n_estimators': 130, 'max_features': 3, 'max_depth': 17}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 17.628421\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "5         130.0           3.0       17.0  0.677176\n",
      "[130.   5.  11.]\n",
      "Pattern move point {'n_estimators': 130, 'max_features': 4, 'max_depth': 11}  has been evaluated\n",
      "Current Delta values for each dimension:  [7, 1, 3]\n",
      "1 {'n_estimators': 200, 'max_features': 3, 'max_depth': 17}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 28.095032\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "5         130.0           3.0       17.0  0.677176\n",
      "6         200.0           3.0       17.0  0.673282\n",
      "-1 {'n_estimators': 60, 'max_features': 3, 'max_depth': 17}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.655039\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "5         130.0           3.0       17.0  0.677176\n",
      "6         200.0           3.0       17.0  0.673282\n",
      "7          60.0           3.0       17.0  0.674194\n",
      "1 {'n_estimators': 130, 'max_features': 4, 'max_depth': 17}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 19.044984\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "5         130.0           3.0       17.0  0.677176\n",
      "6         200.0           3.0       17.0  0.673282\n",
      "7          60.0           3.0       17.0  0.674194\n",
      "8         130.0           4.0       17.0  0.668283\n",
      "-1 {'n_estimators': 130, 'max_features': 2, 'max_depth': 17}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 17.172877\n",
      "   n_estimators  max_features  max_depth     score\n",
      "0         130.0           3.0       11.0  0.669828\n",
      "1         260.0           3.0       11.0  0.667675\n",
      "2          10.0           3.0       11.0  0.666677\n",
      "3         130.0           4.0       11.0  0.662589\n",
      "4         130.0           2.0       11.0  0.653970\n",
      "5         130.0           3.0       17.0  0.677176\n",
      "6         200.0           3.0       17.0  0.673282\n",
      "7          60.0           3.0       17.0  0.674194\n",
      "8         130.0           4.0       17.0  0.668283\n",
      "9         130.0           2.0       17.0  0.675931\n",
      "-1 {'n_estimators': 130, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 12.760186\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "[270.   3.  23.]\n",
      "{'n_estimators': 260, 'max_features': 3, 'max_depth': 17}\n",
      "Executing Pattern Move...\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 34.132210\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "Current Delta values for each dimension:  [4, 1, 2]\n",
      "1 {'n_estimators': 170, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 15.777831\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "-1 {'n_estimators': 90, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.130524\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "1 {'n_estimators': 90, 'max_features': 4, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Time: 10.806602\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "-1 {'n_estimators': 90, 'max_features': 2, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 12.665132\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "1 {'n_estimators': 90, 'max_features': 3, 'max_depth': 16}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 12.843666\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "-1 {'n_estimators': 90, 'max_features': 3, 'max_depth': 12}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 8.812472\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "[130.   5.  23.]\n",
      "Pattern move point {'n_estimators': 130, 'max_features': 4, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [2, 1, 1]\n",
      "1 {'n_estimators': 110, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.773648\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "-1 {'n_estimators': 70, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.293484\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "1 {'n_estimators': 90, 'max_features': 3, 'max_depth': 15}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.318077\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "-1 {'n_estimators': 90, 'max_features': 3, 'max_depth': 13}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.274446\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "[130.   5.  23.]\n",
      "Pattern move point {'n_estimators': 130, 'max_features': 4, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      "1 {'n_estimators': 100, 'max_features': 3, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Time: 10.641041\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "1 {'n_estimators': 100, 'max_features': 4, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.229558\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "23         100.0           4.0       14.0  0.666720\n",
      "-1 {'n_estimators': 100, 'max_features': 2, 'max_depth': 14}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.039486\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "23         100.0           4.0       14.0  0.666720\n",
      "24         100.0           2.0       14.0  0.681387\n",
      "1 {'n_estimators': 100, 'max_features': 3, 'max_depth': 15}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.770578\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "23         100.0           4.0       14.0  0.666720\n",
      "24         100.0           2.0       14.0  0.681387\n",
      "25         100.0           3.0       15.0  0.672315\n",
      "-1 {'n_estimators': 100, 'max_features': 3, 'max_depth': 13}\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.905526\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "23         100.0           4.0       14.0  0.666720\n",
      "24         100.0           2.0       14.0  0.681387\n",
      "25         100.0           3.0       15.0  0.672315\n",
      "26         100.0           3.0       13.0  0.679126\n",
      "[50.  5. 17.]\n",
      "{'n_estimators': 50, 'max_features': 4, 'max_depth': 17}\n",
      "Executing Pattern Move...\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.759517\n",
      "    n_estimators  max_features  max_depth     score\n",
      "0          130.0           3.0       11.0  0.669828\n",
      "1          260.0           3.0       11.0  0.667675\n",
      "2           10.0           3.0       11.0  0.666677\n",
      "3          130.0           4.0       11.0  0.662589\n",
      "4          130.0           2.0       11.0  0.653970\n",
      "5          130.0           3.0       17.0  0.677176\n",
      "6          200.0           3.0       17.0  0.673282\n",
      "7           60.0           3.0       17.0  0.674194\n",
      "8          130.0           4.0       17.0  0.668283\n",
      "9          130.0           2.0       17.0  0.675931\n",
      "10         130.0           3.0       14.0  0.679214\n",
      "11         260.0           3.0       17.0  0.674337\n",
      "12         170.0           3.0       14.0  0.678599\n",
      "13          90.0           3.0       14.0  0.681470\n",
      "14          90.0           4.0       14.0  0.664441\n",
      "15          90.0           2.0       14.0  0.679485\n",
      "16          90.0           3.0       16.0  0.675377\n",
      "17          90.0           3.0       12.0  0.665210\n",
      "18         110.0           3.0       14.0  0.679926\n",
      "19          70.0           3.0       14.0  0.680566\n",
      "20          90.0           3.0       15.0  0.671253\n",
      "21          90.0           3.0       13.0  0.680904\n",
      "22         100.0           3.0       14.0  0.682144\n",
      "23         100.0           4.0       14.0  0.666720\n",
      "24         100.0           2.0       14.0  0.681387\n",
      "25         100.0           3.0       15.0  0.672315\n",
      "26         100.0           3.0       13.0  0.679126\n",
      "27          50.0           4.0       17.0  0.676872\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      "[50.  5. 17.]\n",
      "Pattern move point {'n_estimators': 50, 'max_features': 4, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      "Best Parameters Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n_estimators    100.000000\n",
       "max_features      3.000000\n",
       "max_depth        14.000000\n",
       "score             0.682144\n",
       "Name: 22, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PercentToUse=100\n",
    "alfa=2;Episilon=0.001;k=0\n",
    "Delta=[]\n",
    "Delta.append(2)\n",
    "#len(Space)\n",
    "#print(list(Space.keys())[0])\n",
    "#list(Space.values())[0].midpoint\n",
    "\n",
    "#print(list(Space.values())[0].min)\n",
    "#print(list(Space.values())[0].midpoint)\n",
    "#print(list(Space.values())[0].max)\n",
    "#print(list(Space.values())[0].midptidx)\n",
    "print(list(Space.values())[0].Delta,list(Space.values())[1].Delta,list(Space.values())[2].Delta)\n",
    "print(\" \");print(\" \")\n",
    "\n",
    "xc={}\n",
    "#builds the first exploratory point by collecting the midpoint of each dimension:\n",
    "for Dkey, Dval in Space.items():\n",
    "    xc[Dkey]=Dval.midpoint\n",
    "print(xc)    \n",
    "BestScore,_,_,_,_=CrossEval(PercentToUse,xc)\n",
    "cols=list(xc.keys())\n",
    "cols.append('score')\n",
    "df=pd.DataFrame(columns=cols)\n",
    "xc.update({'score':BestScore})\n",
    "df=df.append(xc, ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "Ndimensions=len(Space);  \n",
    "BestIdx=0; InitialExploration=0\n",
    "\n",
    "# i=exploratory moves iterations; k=Overall Iterations\n",
    "i=0; Continue=0\n",
    "\n",
    "while Continue<3:\n",
    "    #Exploratory Search:\n",
    "    while i < Ndimensions:\n",
    "        k+=1\n",
    "        for Direction in [1,-1]:\n",
    "            xn={}; xd={}\n",
    "            for CurDim in range(0,Ndimensions): #Build the vextor xn:\n",
    "                if i == CurDim:\n",
    "                    NewIndex=list(Space.values())[CurDim].CurrIndex + Direction*list(Space.values())[CurDim].Delta\n",
    "                    #print(NewIndex)\n",
    "                    if NewIndex>len(list(Space.values())[CurDim].value)-1: NewIndex=len(list(Space.values())[CurDim].value)-1\n",
    "                    if NewIndex<0: NewIndex=0\n",
    "                    xn[list(Space.keys())[CurDim]]=list(Space.values())[CurDim].value[NewIndex]\n",
    "                else:\n",
    "                    xn[list(Space.keys())[CurDim]]=list(Space.values())[CurDim].BestValue\n",
    "            if list(xn.values()) not in df.drop(['score'], axis=1).values.tolist():\n",
    "                #print(\"Vetor\",xn,\" nao esta em df. Executando Random Forest\")\n",
    "                print(Direction, xn)            \n",
    "                CurrScore,_,_,_,_=CrossEval(PercentToUse,xn)\n",
    "                #cols=list(xn.keys())\n",
    "                #cols.append('score')\n",
    "                xd=xn.copy()\n",
    "                xd.update({'score':CurrScore})\n",
    "                df=df.append(xd, ignore_index=True)\n",
    "                print(df)\n",
    "                #print(CurrScore)\n",
    "                if CurrScore > BestScore: \n",
    "                    BestScore=CurrScore\n",
    "                    list(Space.values())[i].BestValue=list(Space.values())[i].value[NewIndex]\n",
    "                    list(Space.values())[i].BestIndex=NewIndex\n",
    "                    xc=xn.copy()\n",
    "                    BestIdx=k\n",
    "                    break\n",
    "        list(Space.values())[i].CurrIndex=list(Space.values())[i].BestIndex \n",
    "        i+=1\n",
    "\n",
    "    #xc={}\n",
    "    #for Dkey, Dval in Space.items():\n",
    "    #    xc[Dkey]=Dval.BestValue\n",
    "    #print(xc)\n",
    "\n",
    "    #pattern move:\n",
    "    pm=df.values[BestIdx]+(df.values[BestIdx]-df.values[InitialExploration])\n",
    "    pm=pm[0:(len(pm)-1)]\n",
    "    print(pm)\n",
    "\n",
    "    #picks the closest elements in the lists to the ideal point\n",
    "    n=0\n",
    "    for Dkey, Dval in Space.items():\n",
    "        xn[Dkey]=min(Dval.value, key=lambda x:abs(x-pm[n])) \n",
    "        n+=1\n",
    "\n",
    "    #Evaluates pattern move it it has not been evaluated already:\n",
    "    if list(xn.values()) not in df.drop(['score'], axis=1).values.tolist():\n",
    "        print(xn)\n",
    "        print(\"Executing Pattern Move...\")\n",
    "        k+=1\n",
    "        CurrScore,_,_,_,_=CrossEval(PercentToUse,xn)\n",
    "        xd=xn.copy()\n",
    "        xd.update({'score':CurrScore})\n",
    "        df=df.append(xd, ignore_index=True)\n",
    "        print(df)\n",
    "        if CurrScore > BestScore:\n",
    "            BestScore=CurrScore\n",
    "            xc=xn.copy()\n",
    "            for CurDim in range(0,Ndimensions):\n",
    "                list(Space.values())[CurDim].BestIndex=list(Space.values())[CurDim].value.index(list(xc.values())[CurDim])\n",
    "                list(Space.values())[CurDim].CurrIndex=list(Space.values())[CurDim].BestIndex\n",
    "                list(Space.values())[CurDim].BestValue=list(xc.values())[CurDim]\n",
    "            BestIdx=k\n",
    "            InitialExploration=BestIdx\n",
    "            BestScore=CurrScore\n",
    "        else:\n",
    "            #divide delta by 2\n",
    "            DeltaVector=[]\n",
    "            for CurDim in range(0,Ndimensions):\n",
    "                list(Space.values())[CurDim].Delta=int(0.5+list(Space.values())[CurDim].Delta/alfa)\n",
    "                DeltaVector.append(list(Space.values())[CurDim].Delta)\n",
    "    else:\n",
    "        #divide delta by 2\n",
    "        print(\"Pattern move point\",xn,\" has been evaluated\")\n",
    "        DeltaVector=[]\n",
    "        for CurDim in range(0,Ndimensions):\n",
    "            list(Space.values())[CurDim].Delta=int(0.5+list(Space.values())[CurDim].Delta/alfa)\n",
    "            if list(Space.values())[CurDim].Delta==0: list(Space.values())[CurDim].Delta=1\n",
    "            DeltaVector.append(list(Space.values())[CurDim].Delta)\n",
    "\n",
    "    print(\"Current Delta values for each dimension: \",DeltaVector)\n",
    "    i=0 \n",
    "    if DeltaVector==list(np.ones(3)): Continue+=1\n",
    "\n",
    "print(\"Best Parameters Found:\")\n",
    "df.loc[df['score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T06:43:29.324458Z",
     "start_time": "2019-05-06T06:43:29.308858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 240, 'max_features': 2, 'max_depth': 18}\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "pm=df.values[k]+(df.values[k]-df.values[k-i])\n",
    "pm=pm[0:3]\n",
    "n=0\n",
    "for Dkey, Dval in Space.items():\n",
    "    xc[Dkey]=min(Dval.value, key=lambda x:abs(x-pm[n])) #picks the closes elements in the lists to the ideal point\n",
    "    n+=1\n",
    "print(xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:55:15.217886Z",
     "start_time": "2019-06-10T19:54:59.971526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time Series Cross Validation\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 15.22 seconds for 14 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.571 (std: 0.096)\n",
      "Parameters: {'n_estimators': 25, 'max_features': 4, 'max_depth': 13}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.571 (std: 0.102)\n",
      "Parameters: {'n_estimators': 30, 'max_features': 4, 'max_depth': 13}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.567 (std: 0.107)\n",
      "Parameters: {'n_estimators': 30, 'max_features': 2, 'max_depth': 14}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.566 (std: 0.099)\n",
      "Parameters: {'n_estimators': 35, 'max_features': 3, 'max_depth': 12}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.562 (std: 0.101)\n",
      "Parameters: {'n_estimators': 20, 'max_features': 3, 'max_depth': 15}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.559 (std: 0.104)\n",
      "Parameters: {'n_estimators': 30, 'max_features': 3, 'max_depth': 10}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.557 (std: 0.107)\n",
      "Parameters: {'n_estimators': 20, 'max_features': 3, 'max_depth': 16}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.556 (std: 0.105)\n",
      "Parameters: {'n_estimators': 20, 'max_features': 3, 'max_depth': 14}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.549 (std: 0.108)\n",
      "Parameters: {'n_estimators': 35, 'max_features': 3, 'max_depth': 9}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.541 (std: 0.119)\n",
      "Parameters: {'n_estimators': 30, 'max_features': 4, 'max_depth': 6}\n",
      "\n",
      "Model with rank: 11\n",
      "Mean validation score: 0.538 (std: 0.112)\n",
      "Parameters: {'n_estimators': 35, 'max_features': 4, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 12\n",
      "Mean validation score: 0.536 (std: 0.103)\n",
      "Parameters: {'n_estimators': 35, 'max_features': 2, 'max_depth': 8}\n",
      "\n",
      "Model with rank: 13\n",
      "Mean validation score: 0.501 (std: 0.108)\n",
      "Parameters: {'n_estimators': 30, 'max_features': 3, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 14\n",
      "Mean validation score: 0.443 (std: 0.084)\n",
      "Parameters: {'n_estimators': 25, 'max_features': 2, 'max_depth': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Randomize Search:\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load data\n",
    "X, y = trainDataset_X, trainDataset_y\n",
    "#del(trainDataset_X, trainDataset_y)\n",
    "\n",
    "# build model\n",
    "n_iter_search = 15\n",
    "#clf = GradientBoostingRegressor(verbose=1,\n",
    "#                                loss=\"ls\",\n",
    "#                                n_iter_no_change=3,\n",
    "#                                tol=0.1,\n",
    "#                                random_state=0)\n",
    "#param_dist = {\"n_estimators\": [31,37], #sp_randint(37),\n",
    "#              \"max_depth\": [4,5],\n",
    "#              \"max_features\": [12],\n",
    "#              \"min_samples_split\": [5,10],\n",
    "#              \"min_samples_leaf\" : [1,2]\n",
    "#              }\n",
    "\n",
    "clf = ExtraTreesRegressor(n_estimators=240, \n",
    "                                 max_features = int(X.columns.size - 15),\n",
    "                                 max_depth = 16,\n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "# param_dist={'n_estimators':[230,240,250],\n",
    "#        'max_features':[2,3],\n",
    "#        'max_depth':[16,17,30]}\n",
    "\n",
    "# param_dist={'n_estimators':[20,25,30,35],\n",
    "#        'max_features':[2,3,4],\n",
    "#        'max_depth':list(range(5,18,1))}\n",
    "\n",
    "param_dist={#'n_estimators':[20,25,30,35],\n",
    "       'max_features':[2,3,4],\n",
    "       'n_estimators': list(np.linspace(0, 250, num=26, endpoint=True,dtype=int)+10),\n",
    "       #'lr':list(np.logspace(-2, -5, num=4, endpoint=True, base=10.0)),\n",
    "       'max_depth':list(range(5,18,1))}\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=14):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "print(\"Using Time Series Cross Validation\")\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "#scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=tscv, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )        \n",
    "\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=tscv, n_jobs=-1, verbose=1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:40:07.735039Z",
     "start_time": "2019-06-10T20:40:07.696036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.002013</td>\n",
       "      <td>0.963433</td>\n",
       "      <td>0.591733</td>\n",
       "      <td>0.403261</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 130, 'max_...</td>\n",
       "      <td>0.640238</td>\n",
       "      <td>0.535233</td>\n",
       "      <td>0.648533</td>\n",
       "      <td>0.648520</td>\n",
       "      <td>0.368516</td>\n",
       "      <td>0.568208</td>\n",
       "      <td>0.108678</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478182</td>\n",
       "      <td>0.674848</td>\n",
       "      <td>0.338019</td>\n",
       "      <td>0.240745</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 130, 'max_...</td>\n",
       "      <td>0.642258</td>\n",
       "      <td>0.542479</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.652713</td>\n",
       "      <td>0.382582</td>\n",
       "      <td>0.571646</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.601562</td>\n",
       "      <td>2.191038</td>\n",
       "      <td>0.864249</td>\n",
       "      <td>0.487595</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.640165</td>\n",
       "      <td>0.542508</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.655306</td>\n",
       "      <td>0.382932</td>\n",
       "      <td>0.572041</td>\n",
       "      <td>0.102694</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.006999</td>\n",
       "      <td>3.511457</td>\n",
       "      <td>1.129763</td>\n",
       "      <td>0.632418</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.655224</td>\n",
       "      <td>0.553209</td>\n",
       "      <td>0.595521</td>\n",
       "      <td>0.666836</td>\n",
       "      <td>0.405489</td>\n",
       "      <td>0.575256</td>\n",
       "      <td>0.094339</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.237663</td>\n",
       "      <td>2.994531</td>\n",
       "      <td>1.137862</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.658834</td>\n",
       "      <td>0.558860</td>\n",
       "      <td>0.618489</td>\n",
       "      <td>0.672638</td>\n",
       "      <td>0.396209</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.100498</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.405416</td>\n",
       "      <td>3.277567</td>\n",
       "      <td>1.614790</td>\n",
       "      <td>1.104725</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 190, 'max_...</td>\n",
       "      <td>0.658494</td>\n",
       "      <td>0.557957</td>\n",
       "      <td>0.613764</td>\n",
       "      <td>0.672873</td>\n",
       "      <td>0.394115</td>\n",
       "      <td>0.579441</td>\n",
       "      <td>0.100960</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.701912</td>\n",
       "      <td>2.186335</td>\n",
       "      <td>1.008354</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.654948</td>\n",
       "      <td>0.549471</td>\n",
       "      <td>0.640972</td>\n",
       "      <td>0.661926</td>\n",
       "      <td>0.388270</td>\n",
       "      <td>0.579117</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.350215</td>\n",
       "      <td>2.741219</td>\n",
       "      <td>1.138364</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.667912</td>\n",
       "      <td>0.552474</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0.676205</td>\n",
       "      <td>0.398187</td>\n",
       "      <td>0.586584</td>\n",
       "      <td>0.103886</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.230042</td>\n",
       "      <td>2.223738</td>\n",
       "      <td>1.041753</td>\n",
       "      <td>0.655505</td>\n",
       "      <td>2</td>\n",
       "      <td>220</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 220, 'max_...</td>\n",
       "      <td>0.667595</td>\n",
       "      <td>0.552820</td>\n",
       "      <td>0.636216</td>\n",
       "      <td>0.676780</td>\n",
       "      <td>0.399435</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.805129</td>\n",
       "      <td>2.214159</td>\n",
       "      <td>1.122864</td>\n",
       "      <td>0.685136</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.663775</td>\n",
       "      <td>0.554553</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.668022</td>\n",
       "      <td>0.389275</td>\n",
       "      <td>0.585127</td>\n",
       "      <td>0.106357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.088696</td>\n",
       "      <td>2.126460</td>\n",
       "      <td>1.033657</td>\n",
       "      <td>0.602159</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 240, 'max_...</td>\n",
       "      <td>0.668035</td>\n",
       "      <td>0.552859</td>\n",
       "      <td>0.636320</td>\n",
       "      <td>0.677675</td>\n",
       "      <td>0.398678</td>\n",
       "      <td>0.586714</td>\n",
       "      <td>0.103780</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.076444</td>\n",
       "      <td>2.251869</td>\n",
       "      <td>1.046359</td>\n",
       "      <td>0.667825</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.669155</td>\n",
       "      <td>0.553692</td>\n",
       "      <td>0.648246</td>\n",
       "      <td>0.672126</td>\n",
       "      <td>0.392558</td>\n",
       "      <td>0.587155</td>\n",
       "      <td>0.106456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.182501</td>\n",
       "      <td>2.584975</td>\n",
       "      <td>1.074359</td>\n",
       "      <td>0.761274</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 240, 'max_...</td>\n",
       "      <td>0.662020</td>\n",
       "      <td>0.550759</td>\n",
       "      <td>0.626467</td>\n",
       "      <td>0.674055</td>\n",
       "      <td>0.396360</td>\n",
       "      <td>0.581932</td>\n",
       "      <td>0.102267</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.294655</td>\n",
       "      <td>2.474129</td>\n",
       "      <td>1.113064</td>\n",
       "      <td>0.729800</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 250, 'max_...</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.553838</td>\n",
       "      <td>0.647980</td>\n",
       "      <td>0.672126</td>\n",
       "      <td>0.392275</td>\n",
       "      <td>0.587126</td>\n",
       "      <td>0.106559</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.898734</td>\n",
       "      <td>2.115779</td>\n",
       "      <td>1.024958</td>\n",
       "      <td>0.681605</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 230, 'max_...</td>\n",
       "      <td>0.669344</td>\n",
       "      <td>0.553502</td>\n",
       "      <td>0.648449</td>\n",
       "      <td>0.672628</td>\n",
       "      <td>0.390938</td>\n",
       "      <td>0.586972</td>\n",
       "      <td>0.107192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.236690</td>\n",
       "      <td>2.181860</td>\n",
       "      <td>1.004457</td>\n",
       "      <td>0.648117</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.663631</td>\n",
       "      <td>0.554281</td>\n",
       "      <td>0.650274</td>\n",
       "      <td>0.668340</td>\n",
       "      <td>0.391230</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.105715</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.002013      0.963433         0.591733        0.403261   \n",
       "1        1.478182      0.674848         0.338019        0.240745   \n",
       "2        4.601562      2.191038         0.864249        0.487595   \n",
       "3        9.006999      3.511457         1.129763        0.632418   \n",
       "4        8.237663      2.994531         1.137862        0.604569   \n",
       "5        7.405416      3.277567         1.614790        1.104725   \n",
       "6        5.701912      2.186335         1.008354        0.616404   \n",
       "7        7.350215      2.741219         1.138364        0.642395   \n",
       "8        6.230042      2.223738         1.041753        0.655505   \n",
       "9        5.805129      2.214159         1.122864        0.685136   \n",
       "10       7.088696      2.126460         1.033657        0.602159   \n",
       "11       6.076444      2.251869         1.046359        0.667825   \n",
       "12       7.182501      2.584975         1.074359        0.761274   \n",
       "13       6.294655      2.474129         1.113064        0.729800   \n",
       "14       5.898734      2.115779         1.024958        0.681605   \n",
       "15       5.236690      2.181860         1.004457        0.648117   \n",
       "\n",
       "   param_max_features param_n_estimators param_max_depth  \\\n",
       "0                   3                130              11   \n",
       "1                   4                130              11   \n",
       "2                   4                260              11   \n",
       "3                   4                260              11   \n",
       "4                   3                260              17   \n",
       "5                   3                190              17   \n",
       "6                   4                260              17   \n",
       "7                   2                260              17   \n",
       "8                   2                220              17   \n",
       "9                   3                260              17   \n",
       "10                  2                240              17   \n",
       "11                  2                260              17   \n",
       "12                  3                240              16   \n",
       "13                  2                250              16   \n",
       "14                  2                230              16   \n",
       "15                  2                240              15   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_features': 3, 'n_estimators': 130, 'max_...           0.640238   \n",
       "1   {'max_features': 4, 'n_estimators': 130, 'max_...           0.642258   \n",
       "2   {'max_features': 4, 'n_estimators': 260, 'max_...           0.640165   \n",
       "3   {'max_features': 4, 'n_estimators': 260, 'max_...           0.655224   \n",
       "4   {'max_features': 3, 'n_estimators': 260, 'max_...           0.658834   \n",
       "5   {'max_features': 3, 'n_estimators': 190, 'max_...           0.658494   \n",
       "6   {'max_features': 4, 'n_estimators': 260, 'max_...           0.654948   \n",
       "7   {'max_features': 2, 'n_estimators': 260, 'max_...           0.667912   \n",
       "8   {'max_features': 2, 'n_estimators': 220, 'max_...           0.667595   \n",
       "9   {'max_features': 3, 'n_estimators': 260, 'max_...           0.663775   \n",
       "10  {'max_features': 2, 'n_estimators': 240, 'max_...           0.668035   \n",
       "11  {'max_features': 2, 'n_estimators': 260, 'max_...           0.669155   \n",
       "12  {'max_features': 3, 'n_estimators': 240, 'max_...           0.662020   \n",
       "13  {'max_features': 2, 'n_estimators': 250, 'max_...           0.669410   \n",
       "14  {'max_features': 2, 'n_estimators': 230, 'max_...           0.669344   \n",
       "15  {'max_features': 2, 'n_estimators': 260, 'max_...           0.663631   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.535233           0.648533           0.648520   \n",
       "1            0.542479           0.638197           0.652713   \n",
       "2            0.542508           0.639291           0.655306   \n",
       "3            0.553209           0.595521           0.666836   \n",
       "4            0.558860           0.618489           0.672638   \n",
       "5            0.557957           0.613764           0.672873   \n",
       "6            0.549471           0.640972           0.661926   \n",
       "7            0.552474           0.638144           0.676205   \n",
       "8            0.552820           0.636216           0.676780   \n",
       "9            0.554553           0.650008           0.668022   \n",
       "10           0.552859           0.636320           0.677675   \n",
       "11           0.553692           0.648246           0.672126   \n",
       "12           0.550759           0.626467           0.674055   \n",
       "13           0.553838           0.647980           0.672126   \n",
       "14           0.553502           0.648449           0.672628   \n",
       "15           0.554281           0.650274           0.668340   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.368516         0.568208        0.108678               16  \n",
       "1            0.382582         0.571646        0.102550               15  \n",
       "2            0.382932         0.572041        0.102694               14  \n",
       "3            0.405489         0.575256        0.094339               13  \n",
       "4            0.396209         0.581006        0.100498               10  \n",
       "5            0.394115         0.579441        0.100960               11  \n",
       "6            0.388270         0.579117        0.103668               12  \n",
       "7            0.398187         0.586584        0.103886                5  \n",
       "8            0.399435         0.586569        0.103273                6  \n",
       "9            0.389275         0.585127        0.106357                8  \n",
       "10           0.398678         0.586714        0.103780                4  \n",
       "11           0.392558         0.587155        0.106456                1  \n",
       "12           0.396360         0.581932        0.102267                9  \n",
       "13           0.392275         0.587126        0.106559                2  \n",
       "14           0.390938         0.586972        0.107192                3  \n",
       "15           0.391230         0.585551        0.105715                7  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(pattern_search.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:40:16.408535Z",
     "start_time": "2019-06-10T20:40:16.400534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'max_features': 4, 'max_depth': 13}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5707034560747144"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search\n",
    "print(random_search.best_params_)\n",
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern SearchCV Sklearn Stile (Hooke-Jeeves Method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:26:18.466063Z",
     "start_time": "2019-06-10T19:26:18.384059Z"
    },
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import defaultdict\n",
    "from collections.abc import Mapping, Sequence, Iterable\n",
    "from functools import partial, reduce\n",
    "from itertools import product\n",
    "import operator\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.base import BaseEstimator, is_classifier, clone\n",
    "from sklearn.base import MetaEstimatorMixin\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "from sklearn.model_selection._validation import _aggregate_score_dicts\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.utils._joblib import Parallel, delayed\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.fixes import MaskedArray\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.utils.validation import indexable, check_is_fitted\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "from sklearn.metrics.scorer import _check_multimetric_scoring\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "\n",
    "class BaseSearchCV2(BaseEstimator, MetaEstimatorMixin, metaclass=ABCMeta):\n",
    "    \"\"\"Abstract base class for hyper parameter search with cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, estimator, scoring=None, n_jobs=None, iid='warn',\n",
    "                 refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 error_score='raise-deprecating', return_train_score=True):\n",
    "\n",
    "        self.scoring = scoring\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.iid = iid\n",
    "        self.refit = refit\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.pre_dispatch = pre_dispatch\n",
    "        self.error_score = error_score\n",
    "        self.return_train_score = return_train_score\n",
    "\n",
    "    @property\n",
    "    def _estimator_type(self):\n",
    "        return self.estimator._estimator_type\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"Returns the score on the given data, if the estimator has been refit.\n",
    "        This uses the score defined by ``scoring`` where provided, and the\n",
    "        ``best_estimator_.score`` method otherwise.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Input data, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('score')\n",
    "        if self.scorer_ is None:\n",
    "            raise ValueError(\"No score function explicitly defined, \"\n",
    "                             \"and the estimator doesn't provide one %s\"\n",
    "                             % self.best_estimator_)\n",
    "        score = self.scorer_[self.refit] if self.multimetric_ else self.scorer_\n",
    "        return score(self.best_estimator_, X, y)\n",
    "\n",
    "    def _check_is_fitted(self, method_name):\n",
    "        if not self.refit:\n",
    "            raise NotFittedError('This %s instance was initialized '\n",
    "                                 'with refit=False. %s is '\n",
    "                                 'available only after refitting on the best '\n",
    "                                 'parameters. You can refit an estimator '\n",
    "                                 'manually using the ``best_params_`` '\n",
    "                                 'attribute'\n",
    "                                 % (type(self).__name__, method_name))\n",
    "        else:\n",
    "            check_is_fitted(self, 'best_estimator_')\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict(self, X):\n",
    "        \"\"\"Call predict on the estimator with the best found parameters.\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict')\n",
    "        return self.best_estimator_.predict(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Call predict_proba on the estimator with the best found parameters.\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict_proba``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict_proba')\n",
    "        return self.best_estimator_.predict_proba(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``predict_log_proba``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('predict_log_proba')\n",
    "        return self.best_estimator_.predict_log_proba(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Call decision_function on the estimator with the best found parameters.\n",
    "        Only available if ``refit=True`` and the underlying estimator supports\n",
    "        ``decision_function``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('decision_function')\n",
    "        return self.best_estimator_.decision_function(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def transform(self, X):\n",
    "        \"\"\"Call transform on the estimator with the best found parameters.\n",
    "        Only available if the underlying estimator supports ``transform`` and\n",
    "        ``refit=True``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('transform')\n",
    "        return self.best_estimator_.transform(X)\n",
    "\n",
    "    @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n",
    "    def inverse_transform(self, Xt):\n",
    "        \"\"\"Call inverse_transform on the estimator with the best found params.\n",
    "        Only available if the underlying estimator implements\n",
    "        ``inverse_transform`` and ``refit=True``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        Xt : indexable, length n_samples\n",
    "            Must fulfill the input assumptions of the\n",
    "            underlying estimator.\n",
    "        \"\"\"\n",
    "        self._check_is_fitted('inverse_transform')\n",
    "        return self.best_estimator_.inverse_transform(Xt)\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        self._check_is_fitted(\"classes_\")\n",
    "        return self.best_estimator_.classes_\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Repeatedly calls `evaluate_candidates` to conduct a search.\n",
    "        This method, implemented in sub-classes, makes it possible to\n",
    "        customize the the scheduling of evaluations: GridSearchCV and\n",
    "        RandomizedSearchCV schedule evaluations for their whole parameter\n",
    "        search space at once but other more sequential approaches are also\n",
    "        possible: for instance is possible to iteratively schedule evaluations\n",
    "        for new regions of the parameter search space based on previously\n",
    "        collected evaluation results. This makes it possible to implement\n",
    "        Bayesian optimization or more generally sequential model-based\n",
    "        optimization by deriving from the BaseSearchCV abstract base class.\n",
    "        Parameters\n",
    "        ----------\n",
    "        evaluate_candidates : callable\n",
    "            This callback accepts a list of candidates, where each candidate is\n",
    "            a dict of parameter settings. It returns a dict of all results so\n",
    "            far, formatted like ``cv_results_``.\n",
    "        Examples\n",
    "        --------\n",
    "        ::\n",
    "            def _run_search(self, evaluate_candidates):\n",
    "                'Try C=0.1 only if C=1 is better than C=10'\n",
    "                all_results = evaluate_candidates([{'C': 1}, {'C': 10}])\n",
    "                score = all_results['mean_test_score']\n",
    "                if score[0] < score[1]:\n",
    "                    evaluate_candidates([{'C': 0.1}])\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"_run_search not implemented.\")\n",
    "\n",
    "    def fit(self, X, y=None, groups=None, **fit_params):\n",
    "        \"\"\"Run fit with all sets of parameters.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "        groups : array-like, with shape (n_samples,), optional\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``fit`` method of the estimator\n",
    "        \"\"\"\n",
    "        estimator = self.estimator\n",
    "        cv = check_cv(self.cv, y, classifier=is_classifier(estimator))\n",
    "\n",
    "        scorers, self.multimetric_ = _check_multimetric_scoring(\n",
    "            self.estimator, scoring=self.scoring)\n",
    "\n",
    "        if self.multimetric_:\n",
    "            if self.refit is not False and (\n",
    "                    not isinstance(self.refit, str) or\n",
    "                    # This will work for both dict / list (tuple)\n",
    "                    self.refit not in scorers) and not callable(self.refit):\n",
    "                raise ValueError(\"For multi-metric scoring, the parameter \"\n",
    "                                 \"refit must be set to a scorer key or a \"\n",
    "                                 \"callable to refit an estimator with the \"\n",
    "                                 \"best parameter setting on the whole \"\n",
    "                                 \"data and make the best_* attributes \"\n",
    "                                 \"available for that metric. If this is \"\n",
    "                                 \"not needed, refit should be set to \"\n",
    "                                 \"False explicitly. %r was passed.\"\n",
    "                                 % self.refit)\n",
    "            else:\n",
    "                refit_metric = self.refit\n",
    "        else:\n",
    "            refit_metric = 'score'\n",
    "\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "\n",
    "        base_estimator = clone(self.estimator)\n",
    "\n",
    "        parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "                            pre_dispatch=self.pre_dispatch)\n",
    "\n",
    "        fit_and_score_kwargs = dict(scorer=scorers,\n",
    "                                    fit_params=fit_params,\n",
    "                                    return_train_score=self.return_train_score,\n",
    "                                    return_n_test_samples=True,\n",
    "                                    return_times=True,\n",
    "                                    return_parameters=False,\n",
    "                                    error_score=self.error_score,\n",
    "                                    verbose=self.verbose)\n",
    "        results = {}\n",
    "        with parallel:\n",
    "            all_candidate_params = []\n",
    "            all_out = []\n",
    "\n",
    "            def evaluate_candidates(candidate_params):\n",
    "                candidate_params = list(candidate_params)\n",
    "                n_candidates = len(candidate_params)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Fitting {0} folds for each of {1} candidates,\"\n",
    "                          \" totalling {2} fits\".format(\n",
    "                              n_splits, n_candidates, n_candidates * n_splits))\n",
    "\n",
    "                out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n",
    "                                                       X, y,\n",
    "                                                       train=train, test=test,\n",
    "                                                       parameters=parameters,\n",
    "                                                       **fit_and_score_kwargs)\n",
    "                               for parameters, (train, test)\n",
    "                               in product(candidate_params,\n",
    "                                          cv.split(X, y, groups)))\n",
    "\n",
    "                if len(out) < 1:\n",
    "                    raise ValueError('No fits were performed. '\n",
    "                                     'Was the CV iterator empty? '\n",
    "                                     'Were there no candidates?')\n",
    "                elif len(out) != n_candidates * n_splits:\n",
    "                    raise ValueError('cv.split and cv.get_n_splits returned '\n",
    "                                     'inconsistent results. Expected {} '\n",
    "                                     'splits, got {}'\n",
    "                                     .format(n_splits,\n",
    "                                             len(out) // n_candidates))\n",
    "\n",
    "                all_candidate_params.extend(candidate_params)\n",
    "                all_out.extend(out)\n",
    "\n",
    "                nonlocal results\n",
    "                results = self._format_results(\n",
    "                    all_candidate_params, scorers, n_splits, all_out)\n",
    "                return results\n",
    "\n",
    "            self._run_search(evaluate_candidates)\n",
    "\n",
    "        # For multi-metric evaluation, store the best_index_, best_params_ and\n",
    "        # best_score_ iff refit is one of the scorer names\n",
    "        # In single metric evaluation, refit_metric is \"score\"\n",
    "        if self.refit or not self.multimetric_:\n",
    "            # If callable, refit is expected to return the index of the best\n",
    "            # parameter set.\n",
    "            if callable(self.refit):\n",
    "                self.best_index_ = self.refit(results)\n",
    "                if not isinstance(self.best_index_, (int, np.integer)):\n",
    "                    raise TypeError('best_index_ returned is not an integer')\n",
    "                if (self.best_index_ < 0 or\n",
    "                   self.best_index_ >= len(results[\"params\"])):\n",
    "                    raise IndexError('best_index_ index out of range')\n",
    "            else:\n",
    "                self.best_index_ = results[\"rank_test_%s\"\n",
    "                                           % refit_metric].argmin()\n",
    "                self.best_score_ = results[\"mean_test_%s\" % refit_metric][\n",
    "                                           self.best_index_]\n",
    "            self.best_params_ = results[\"params\"][self.best_index_]\n",
    "\n",
    "        if self.refit:\n",
    "            self.best_estimator_ = clone(base_estimator).set_params(\n",
    "                **self.best_params_)\n",
    "            refit_start_time = time()\n",
    "            if y is not None:\n",
    "                self.best_estimator_.fit(X, y, **fit_params)\n",
    "            else:\n",
    "                self.best_estimator_.fit(X, **fit_params)\n",
    "            refit_end_time = time()\n",
    "            self.refit_time_ = refit_end_time - refit_start_time\n",
    "\n",
    "        # Store the only scorer not as a dict for single metric evaluation\n",
    "        self.scorer_ = scorers if self.multimetric_ else scorers['score']\n",
    "        #print(\"results: \", results)\n",
    "        self.cv_results_ = results\n",
    "        self.n_splits_ = n_splits\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _format_results(self, candidate_params, scorers, n_splits, out):\n",
    "        n_candidates = len(candidate_params)\n",
    "        # if one choose to see train score, \"out\" will contain train score info\n",
    "        if self.return_train_score:\n",
    "            (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n",
    "             score_time) = zip(*out)\n",
    "        else:\n",
    "            (test_score_dicts, test_sample_counts, fit_time,\n",
    "             score_time) = zip(*out)\n",
    "\n",
    "        # test_score_dicts and train_score dicts are lists of dictionaries and\n",
    "        # we make them into dict of lists\n",
    "        test_scores = _aggregate_score_dicts(test_score_dicts)\n",
    "        \n",
    "        if self.return_train_score:\n",
    "            train_scores = _aggregate_score_dicts(train_score_dicts)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        def _store(key_name, array, weights=None, splits=False, rank=False):\n",
    "            \"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n",
    "            # When iterated first by splits, then by parameters\n",
    "            # We want `array` to have `n_candidates` rows and `n_splits` cols.\n",
    "            array = np.array(array, dtype=np.float64).reshape(n_candidates,\n",
    "                                                              n_splits)\n",
    "            if splits:\n",
    "                for split_i in range(n_splits):\n",
    "                    # Uses closure to alter the results\n",
    "                    results[\"split%d_%s\"\n",
    "                            % (split_i, key_name)] = array[:, split_i]\n",
    "\n",
    "            array_means = np.average(array, axis=1, weights=weights)\n",
    "            results['mean_%s' % key_name] = array_means\n",
    "            # Weighted std is not directly available in numpy\n",
    "            array_stds = np.sqrt(np.average((array -\n",
    "                                             array_means[:, np.newaxis]) ** 2,\n",
    "                                            axis=1, weights=weights))\n",
    "            results['std_%s' % key_name] = array_stds\n",
    "\n",
    "            if rank:\n",
    "                results[\"rank_%s\" % key_name] = np.asarray(\n",
    "                    rankdata(-array_means, method='min'), dtype=np.int32)\n",
    "\n",
    "        _store('fit_time', fit_time)\n",
    "        _store('score_time', score_time)\n",
    "        # Use one MaskedArray and mask all the places where the param is not\n",
    "        # applicable for that candidate. Use defaultdict as each candidate may\n",
    "        # not contain all the params\n",
    "        param_results = defaultdict(partial(MaskedArray,\n",
    "                                            np.empty(n_candidates,),\n",
    "                                            mask=True,\n",
    "                                            dtype=object))\n",
    "        for cand_i, params in enumerate(candidate_params):\n",
    "            for name, value in params.items():\n",
    "                # An all masked empty array gets created for the key\n",
    "                # `\"param_%s\" % name` at the first occurrence of `name`.\n",
    "                # Setting the value at an index also unmasks that index\n",
    "                param_results[\"param_%s\" % name][cand_i] = value\n",
    "\n",
    "        results.update(param_results)\n",
    "        # Store a list of param dicts at the key 'params'\n",
    "        results['params'] = candidate_params\n",
    "\n",
    "        # NOTE test_sample counts (weights) remain the same for all candidates\n",
    "        test_sample_counts = np.array(test_sample_counts[:n_splits],\n",
    "                                      dtype=np.int)\n",
    "        iid = self.iid\n",
    "        if self.iid == 'warn':\n",
    "            warn = False\n",
    "            for scorer_name in scorers.keys():\n",
    "                scores = test_scores[scorer_name].reshape(n_candidates,\n",
    "                                                          n_splits)\n",
    "                means_weighted = np.average(scores, axis=1,\n",
    "                                            weights=test_sample_counts)\n",
    "                means_unweighted = np.average(scores, axis=1)\n",
    "                if not np.allclose(means_weighted, means_unweighted,\n",
    "                                   rtol=1e-4, atol=1e-4):\n",
    "                    warn = True\n",
    "                    break\n",
    "\n",
    "            if warn:\n",
    "                warnings.warn(\"The default of the `iid` parameter will change \"\n",
    "                              \"from True to False in version 0.22 and will be\"\n",
    "                              \" removed in 0.24. This will change numeric\"\n",
    "                              \" results when test-set sizes are unequal.\",\n",
    "                              DeprecationWarning)\n",
    "            iid = True\n",
    "\n",
    "        for scorer_name in scorers.keys():\n",
    "            # Computed the (weighted) mean and std for test scores alone\n",
    "            _store('test_%s' % scorer_name, test_scores[scorer_name],\n",
    "                   splits=True, rank=True,\n",
    "                   weights=test_sample_counts if iid else None)\n",
    "            if self.return_train_score:\n",
    "                _store('train_%s' % scorer_name, train_scores[scorer_name],\n",
    "                       splits=True)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T21:03:16.208455Z",
     "start_time": "2019-06-10T21:03:16.149451Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class PatternSearchCV(BaseSearchCV2):\n",
    "    _required_parameters = [\"estimator\", \"param_distributions\"]\n",
    "\n",
    "    def __init__(self, estimator, param_distributions, scoring=None, #n_iter=10,\n",
    "                 n_jobs=None, iid='warn', refit=True,\n",
    "                 cv='warn', verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 random_state=None, error_score='raise-deprecating',\n",
    "                 return_train_score=False):\n",
    "        self.param_distributions = param_distributions\n",
    "        #self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        super().__init__(\n",
    "            estimator=estimator, scoring=scoring,\n",
    "            n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "        self.ResultDf = pd.DataFrame()\n",
    "\n",
    "#     param_dist={'n_estimators':[230,240,250],\n",
    "#            'max_features':[2,3],\n",
    "#            'max_depth':[16,17,30]}        \n",
    "        \n",
    "        class Dimension():\n",
    "            def __init__(self, value):\n",
    "                #If value is a Tuple, divide the interval into \"length\" equaly spaced intervals:\n",
    "                if isinstance(value,tuple):\n",
    "                   lower=value[0];upper=value[1];length=value[2]\n",
    "                   value=[lower + x*(upper-lower)/(length-1) for x in range(length)]\n",
    "                self.value=value\n",
    "                self.value.sort()\n",
    "                self.min=self.value[0]\n",
    "                self.max=self.value[-1]\n",
    "                self.midptidx=int((len(self.value)/2)-0.5)\n",
    "                self.midpoint=self.value[self.midptidx]\n",
    "                self.Delta=(len(value)-1)-self.midptidx\n",
    "                self.BestValue=self.midpoint\n",
    "                self.CurrIndex=self.midptidx\n",
    "                self.BestIndex=self.midptidx\n",
    "        \n",
    "        self.Space={}\n",
    "        for Dkey, Dval in param_dist.items():\n",
    "            self.Space[Dkey]=Dimension(Dval)\n",
    "            print(Dkey,\":\",Dval) \n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Search best parameters using Pattern Search Method\"\"\"\n",
    "        #        PercentToUse=20\n",
    "        alfa=2; Episilon=0.001; k=0\n",
    "        Ndimensions=len(self.Space); \n",
    "\n",
    "        xc={}; xd={}\n",
    "        #builds the first exploratory point by collecting the midpoint of each dimension:\n",
    "        for Dkey, Dval in self.Space.items():\n",
    "            xc[Dkey]=Dval.midpoint   \n",
    "\n",
    "\n",
    "        DeltaVector=[]\n",
    "        for CurDim in range(0,Ndimensions):\n",
    "            DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "        print(\" \")\n",
    "        print(\"Current Delta values for each dimension: \", DeltaVector)\n",
    "\n",
    "        BestScore = evaluate_candidates([xc])['mean_test_score'][-1]\n",
    "        print(\" \")\n",
    "        print(xc)\n",
    "\n",
    "        cols=list(xc.keys())\n",
    "        cols.append('score')\n",
    "        df=pd.DataFrame(columns=cols)\n",
    "        xd=xc.copy()\n",
    "        xd.update({'score':BestScore})\n",
    "        df=df.append(xd, ignore_index=True)\n",
    "        print(df)\n",
    "\n",
    "        BestIdx=0; InitialExploration=0\n",
    "\n",
    "        # i=exploratory moves iterations; k=Overall Iterations\n",
    "        i=0; Continue=0\n",
    "\n",
    "        while Continue<3:\n",
    "            #Exploratory Search:\n",
    "            while i < Ndimensions:\n",
    "                k+=1\n",
    "                for Direction in [1,-1]:\n",
    "                    xn={}; xd={}\n",
    "                    for CurDim in range(0,Ndimensions): #Build the vector xn:\n",
    "                        if i == CurDim:\n",
    "                            NewIndex=list(self.Space.values())[CurDim].CurrIndex + Direction*list(self.Space.values())[CurDim].Delta\n",
    "                            #print(NewIndex)\n",
    "                            if NewIndex>len(list(self.Space.values())[CurDim].value)-1: NewIndex=len(list(self.Space.values())[CurDim].value)-1\n",
    "                            if NewIndex<0: NewIndex=0\n",
    "                            xn[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].value[NewIndex]\n",
    "                        else:\n",
    "                            xn[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].BestValue\n",
    "                    if list(xn.values()) not in df.drop(['score'], axis=1).values.tolist():\n",
    "                        #print(\"Vetor\",xn,\" nao esta em df. Executando Random Forest\")\n",
    "                        print(Direction, xn)            \n",
    "                        CurrScore = evaluate_candidates([xn])['mean_test_score'][-1]\n",
    "                        #cols=list(xn.keys())\n",
    "                        #cols.append('score')\n",
    "                        xd=xn.copy()\n",
    "                        xd.update({'score':CurrScore})\n",
    "                        df=df.append(xd, ignore_index=True)\n",
    "                        print(df)\n",
    "                        #print(CurrScore)\n",
    "                        if CurrScore > BestScore: \n",
    "                            BestScore=CurrScore\n",
    "                            list(self.Space.values())[i].BestValue=list(self.Space.values())[i].value[NewIndex]\n",
    "                            list(self.Space.values())[i].BestIndex=NewIndex\n",
    "                            #xc=xn.copy()\n",
    "                            BestIdx=k-1\n",
    "                            break\n",
    "                list(self.Space.values())[i].CurrIndex=list(self.Space.values())[i].BestIndex \n",
    "                i+=1\n",
    "\n",
    "            #pattern move:\n",
    "            pm=df.values[BestIdx]+(df.values[BestIdx]-df.values[InitialExploration])\n",
    "            pm=pm[0:(len(pm)-1)]\n",
    "            print(\"Theoretical Pattern Move: \",pm)\n",
    "\n",
    "            #picks the closest elements in the lists to the ideal point\n",
    "            n=0\n",
    "            for Dkey, Dval in self.Space.items():\n",
    "                xn[Dkey]=min(Dval.value, key=lambda x:abs(x-pm[n])) \n",
    "                n+=1\n",
    "\n",
    "            #Evaluates pattern move it it has not been evaluated already:\n",
    "            if list(xn.values()) not in df.drop(['score'], axis=1).values.tolist():\n",
    "                print(xn)\n",
    "                print(\"Executing Pattern Move...\")\n",
    "                k+=1\n",
    "                CurrScore = evaluate_candidates([xn])['mean_test_score'][-1]\n",
    "                xd=xn.copy()\n",
    "                xd.update({'score':CurrScore})\n",
    "                df=df.append(xd, ignore_index=True)\n",
    "                print(df)\n",
    "                if CurrScore > BestScore:\n",
    "                    BestScore=CurrScore\n",
    "                    xc=xn.copy()\n",
    "                    for CurDim in range(0,Ndimensions):\n",
    "                        list(self.Space.values())[CurDim].BestIndex=list(self.Space.values())[CurDim].value.index(list(xc.values())[CurDim])\n",
    "                        list(self.Space.values())[CurDim].CurrIndex=list(self.Space.values())[CurDim].BestIndex\n",
    "                        list(self.Space.values())[CurDim].BestValue=list(xc.values())[CurDim]\n",
    "                    BestIdx=k\n",
    "                    InitialExploration=BestIdx\n",
    "                    BestScore=CurrScore\n",
    "                else:\n",
    "                    #divide delta by 2\n",
    "                    DeltaVector=[]\n",
    "                    for CurDim in range(0,Ndimensions):\n",
    "                        list(self.Space.values())[CurDim].Delta=int(0.5+list(self.Space.values())[CurDim].Delta/alfa)\n",
    "                        DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "            else:\n",
    "                #divide delta by 2\n",
    "                print(\"Nearest Pattern move point\",xn,\" has been evaluated\")\n",
    "                DeltaVector=[]\n",
    "                for CurDim in range(0,Ndimensions):\n",
    "                    list(self.Space.values())[CurDim].Delta=int(0.5+list(self.Space.values())[CurDim].Delta/alfa)\n",
    "                    if list(self.Space.values())[CurDim].Delta==0: list(self.Space.values())[CurDim].Delta=1\n",
    "                    DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "\n",
    "            print(\"Current Delta values for each dimension: \",DeltaVector)\n",
    "            i=0 \n",
    "            if DeltaVector==list(np.ones(3)): Continue+=1\n",
    "\n",
    "        print(\" \");print(\" \")\n",
    "        print(\"Best Parameters Found:\")\n",
    "        print(df.loc[df['score'].idxmax()])\n",
    "        print(\" \");print(\" \")\n",
    "        self.ResultDf=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:46:27.523094Z",
     "start_time": "2019-06-10T23:44:01.861800Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time Series Cross Validation\n",
      "max_features : [2, 3, 4]\n",
      "n_estimators : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260]\n",
      "max_depth : [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      " \n",
      "Current Delta values for each dimension:  [1, 13, 6]\n",
      " \n",
      "{'max_features': 3, 'n_estimators': 130, 'max_depth': 11}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1 {'max_features': 4, 'n_estimators': 130, 'max_depth': 11}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "1 {'max_features': 4, 'n_estimators': 260, 'max_depth': 11}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "1 {'max_features': 4, 'n_estimators': 260, 'max_depth': 17}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "Theoretical Pattern Move:  [  5. 390.  11.]\n",
      "Nearest Pattern move point {'max_features': 4, 'n_estimators': 260, 'max_depth': 11}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 7, 3]\n",
      "-1 {'max_features': 3, 'n_estimators': 260, 'max_depth': 17}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "-1 {'max_features': 3, 'n_estimators': 190, 'max_depth': 17}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "5           3.0         190.0       17.0  0.579441\n",
      "-1 {'max_features': 3, 'n_estimators': 260, 'max_depth': 14}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "5           3.0         190.0       17.0  0.579441\n",
      "6           3.0         260.0       14.0  0.579117\n",
      "Theoretical Pattern Move:  [  5. 390.  23.]\n",
      "Nearest Pattern move point {'max_features': 4, 'n_estimators': 260, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 4, 2]\n",
      "-1 {'max_features': 2, 'n_estimators': 260, 'max_depth': 17}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "5           3.0         190.0       17.0  0.579441\n",
      "6           3.0         260.0       14.0  0.579117\n",
      "7           2.0         260.0       17.0  0.586584\n",
      "-1 {'max_features': 2, 'n_estimators': 220, 'max_depth': 17}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "5           3.0         190.0       17.0  0.579441\n",
      "6           3.0         260.0       14.0  0.579117\n",
      "7           2.0         260.0       17.0  0.586584\n",
      "8           2.0         220.0       17.0  0.586569\n",
      "-1 {'max_features': 2, 'n_estimators': 260, 'max_depth': 15}\n",
      "   max_features  n_estimators  max_depth     score\n",
      "0           3.0         130.0       11.0  0.568208\n",
      "1           4.0         130.0       11.0  0.571646\n",
      "2           4.0         260.0       11.0  0.572041\n",
      "3           4.0         260.0       17.0  0.575256\n",
      "4           3.0         260.0       17.0  0.581006\n",
      "5           3.0         190.0       17.0  0.579441\n",
      "6           3.0         260.0       14.0  0.579117\n",
      "7           2.0         260.0       17.0  0.586584\n",
      "8           2.0         220.0       17.0  0.586569\n",
      "9           2.0         260.0       15.0  0.585127\n",
      "Theoretical Pattern Move:  [  3. 390.  17.]\n",
      "Nearest Pattern move point {'max_features': 3, 'n_estimators': 260, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 2, 1]\n",
      "-1 {'max_features': 2, 'n_estimators': 240, 'max_depth': 17}\n",
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "-1 {'max_features': 2, 'n_estimators': 240, 'max_depth': 16}\n",
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "11           2.0         240.0       16.0  0.587155\n",
      "Theoretical Pattern Move:  [  1. 350.  21.]\n",
      "Nearest Pattern move point {'max_features': 2, 'n_estimators': 260, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      "1 {'max_features': 3, 'n_estimators': 240, 'max_depth': 16}\n",
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "11           2.0         240.0       16.0  0.587155\n",
      "12           3.0         240.0       16.0  0.581932\n",
      "1 {'max_features': 2, 'n_estimators': 250, 'max_depth': 16}\n",
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "11           2.0         240.0       16.0  0.587155\n",
      "12           3.0         240.0       16.0  0.581932\n",
      "13           2.0         250.0       16.0  0.587126\n",
      "-1 {'max_features': 2, 'n_estimators': 230, 'max_depth': 16}\n",
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "11           2.0         240.0       16.0  0.587155\n",
      "12           3.0         240.0       16.0  0.581932\n",
      "13           2.0         250.0       16.0  0.587126\n",
      "14           2.0         230.0       16.0  0.586972\n",
      "-1 {'max_features': 2, 'n_estimators': 240, 'max_depth': 15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_features  n_estimators  max_depth     score\n",
      "0            3.0         130.0       11.0  0.568208\n",
      "1            4.0         130.0       11.0  0.571646\n",
      "2            4.0         260.0       11.0  0.572041\n",
      "3            4.0         260.0       17.0  0.575256\n",
      "4            3.0         260.0       17.0  0.581006\n",
      "5            3.0         190.0       17.0  0.579441\n",
      "6            3.0         260.0       14.0  0.579117\n",
      "7            2.0         260.0       17.0  0.586584\n",
      "8            2.0         220.0       17.0  0.586569\n",
      "9            2.0         260.0       15.0  0.585127\n",
      "10           2.0         240.0       17.0  0.586714\n",
      "11           2.0         240.0       16.0  0.587155\n",
      "12           3.0         240.0       16.0  0.581932\n",
      "13           2.0         250.0       16.0  0.587126\n",
      "14           2.0         230.0       16.0  0.586972\n",
      "15           2.0         240.0       15.0  0.585551\n",
      "Theoretical Pattern Move:  [  1. 350.  21.]\n",
      "Nearest Pattern move point {'max_features': 2, 'n_estimators': 260, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      "Theoretical Pattern Move:  [  1. 350.  21.]\n",
      "Nearest Pattern move point {'max_features': 2, 'n_estimators': 260, 'max_depth': 17}  has been evaluated\n",
      "Current Delta values for each dimension:  [1, 1, 1]\n",
      " \n",
      " \n",
      "Best Parameters Found:\n",
      "max_features      2.000000\n",
      "n_estimators    240.000000\n",
      "max_depth        16.000000\n",
      "score             0.587155\n",
      "Name: 11, dtype: float64\n",
      " \n",
      " \n",
      "PatternSearchCV took 145.64 seconds \n",
      "Model with rank: 1\n",
      "Mean validation score: 0.587 (std: 0.106)\n",
      "Parameters: {'max_features': 2, 'n_estimators': 260, 'max_depth': 17}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.587 (std: 0.107)\n",
      "Parameters: {'max_features': 2, 'n_estimators': 250, 'max_depth': 16}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.587 (std: 0.107)\n",
      "Parameters: {'max_features': 2, 'n_estimators': 230, 'max_depth': 16}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Execute Pattern Search:\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Load data\n",
    "SplitPercent=100\n",
    "Nrows,_=trainDataset_X.shape\n",
    "SplitPoint=int(Nrows*(SplitPercent/100))\n",
    "X, y = trainDataset_X.iloc[:SplitPoint, :], trainDataset_y.iloc[:SplitPoint]\n",
    "\n",
    "\n",
    "# build model\n",
    "\n",
    "clf = ExtraTreesRegressor(n_estimators=240, \n",
    "                                 max_features = int(X.columns.size - 15),\n",
    "                                 max_depth = 16,\n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "\n",
    "param_dist={#'n_estimators':[20,25,30,35],\n",
    "           'max_features':[2,3,4],\n",
    "           'n_estimators': list(np.linspace(0, 250, num=26, endpoint=True,dtype=int)+10),\n",
    "           #'lr':list(np.logspace(-2, -5, num=4, endpoint=True, base=10.0)),\n",
    "           'max_depth':list(range(5,18,1))}\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "print(\"Using Time Series Cross Validation\")\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "#scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=tscv, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )        \n",
    "\n",
    "\n",
    "# run randomized search\n",
    "pattern_search = PatternSearchCV(clf, param_distributions=param_dist,\n",
    "                                    cv=tscv, n_jobs=-1, verbose=0) \n",
    "\n",
    "start = time()\n",
    "pattern_search.fit(X, y)\n",
    "print(\"PatternSearchCV took %.2f seconds \" % ((time() - start)))\n",
    "report(pattern_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Search Best Result:\n",
    "Use this run to compare with Baysian Opt and Random Search.  They all use the R2 as scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:46:39.344609Z",
     "start_time": "2019-06-10T23:46:39.339608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 2, 'n_estimators': 260, 'max_depth': 17}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5871554790932797"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pattern_search.best_params_)\n",
    "pattern_search.best_score_\n",
    "# Random Search best result: 0.5781305500164665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:46:44.104875Z",
     "start_time": "2019-06-10T23:46:44.089874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.568208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.571646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.572041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.575256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.581006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.579441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.579117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.586584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.586569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.585127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.586714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.587155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.581932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.587126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.586972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.585551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features  n_estimators  max_depth     score\n",
       "0            3.0         130.0       11.0  0.568208\n",
       "1            4.0         130.0       11.0  0.571646\n",
       "2            4.0         260.0       11.0  0.572041\n",
       "3            4.0         260.0       17.0  0.575256\n",
       "4            3.0         260.0       17.0  0.581006\n",
       "5            3.0         190.0       17.0  0.579441\n",
       "6            3.0         260.0       14.0  0.579117\n",
       "7            2.0         260.0       17.0  0.586584\n",
       "8            2.0         220.0       17.0  0.586569\n",
       "9            2.0         260.0       15.0  0.585127\n",
       "10           2.0         240.0       17.0  0.586714\n",
       "11           2.0         240.0       16.0  0.587155\n",
       "12           3.0         240.0       16.0  0.581932\n",
       "13           2.0         250.0       16.0  0.587126\n",
       "14           2.0         230.0       16.0  0.586972\n",
       "15           2.0         240.0       15.0  0.585551"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_search.ResultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T20:27:24.552434Z",
     "start_time": "2019-06-08T20:27:24.542433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_estimators', 'max_features', 'max_depth'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_search.best_params_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T22:14:49.008182Z",
     "start_time": "2019-06-08T22:14:48.990181Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.48050895, 0.36431847, 0.67163854, 1.27307277, 1.08966236,\n",
       "        1.23496981, 0.76223288, 1.09006224, 1.02455163, 0.85524883,\n",
       "        0.66843071, 0.95714607, 0.84784842, 0.6324224 ]),\n",
       " 'std_fit_time': array([0.1813148 , 0.14772076, 0.26696731, 0.48774749, 0.40231914,\n",
       "        0.43756821, 0.25532818, 0.28173014, 0.42833687, 0.25213136,\n",
       "        0.23526333, 0.32068722, 0.32227131, 0.22035381]),\n",
       " 'mean_score_time': array([0.21640677, 0.17180839, 0.32061839, 0.50442891, 0.37502141,\n",
       "        0.36351976, 0.30201726, 0.29421692, 0.40432181, 0.29321599,\n",
       "        0.26521525, 0.34491925, 0.33671846, 0.27981529]),\n",
       " 'std_score_time': array([0.15836207, 0.08317504, 0.18439555, 0.40556355, 0.28216715,\n",
       "        0.34349072, 0.16225219, 0.24750583, 0.34167647, 0.22401916,\n",
       "        0.13415586, 0.30355281, 0.23317626, 0.14824421]),\n",
       " 'param_n_estimators': masked_array(data=[25, 35, 35, 35, 30, 35, 35, 30, 35, 35, 30, 35, 35, 35],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[3, 3, 4, 4, 4, 3, 3, 3, 2, 2, 2, 3, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[11, 11, 11, 17, 17, 17, 17, 17, 17, 17, 15, 15, 16, 14],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 25, 'max_features': 3, 'max_depth': 11},\n",
       "  {'n_estimators': 35, 'max_features': 3, 'max_depth': 11},\n",
       "  {'n_estimators': 35, 'max_features': 4, 'max_depth': 11},\n",
       "  {'n_estimators': 35, 'max_features': 4, 'max_depth': 17},\n",
       "  {'n_estimators': 30, 'max_features': 4, 'max_depth': 17},\n",
       "  {'n_estimators': 35, 'max_features': 3, 'max_depth': 17},\n",
       "  {'n_estimators': 35, 'max_features': 3, 'max_depth': 17},\n",
       "  {'n_estimators': 30, 'max_features': 3, 'max_depth': 17},\n",
       "  {'n_estimators': 35, 'max_features': 2, 'max_depth': 17},\n",
       "  {'n_estimators': 35, 'max_features': 2, 'max_depth': 17},\n",
       "  {'n_estimators': 30, 'max_features': 2, 'max_depth': 15},\n",
       "  {'n_estimators': 35, 'max_features': 3, 'max_depth': 15},\n",
       "  {'n_estimators': 35, 'max_features': 2, 'max_depth': 16},\n",
       "  {'n_estimators': 35, 'max_features': 2, 'max_depth': 17}],\n",
       " 'split0_test_score': array([0.62690852, 0.6241186 , 0.6340784 , 0.65280197, 0.64994174,\n",
       "        0.64216056, 0.63691754, 0.64513918, 0.65923495, 0.65701756,\n",
       "        0.65419678, 0.64179437, 0.65603661, 0.6380258 ]),\n",
       " 'split1_test_score': array([0.52684055, 0.52891262, 0.53854051, 0.55020449, 0.55116374,\n",
       "        0.55416572, 0.54626759, 0.5559179 , 0.5487712 , 0.54589605,\n",
       "        0.54545188, 0.54190745, 0.54857984, 0.53833961]),\n",
       " 'split2_test_score': array([0.62908213, 0.63846567, 0.63874121, 0.58017899, 0.58082857,\n",
       "        0.61220368, 0.61242629, 0.60846079, 0.61098173, 0.65313584,\n",
       "        0.6552544 , 0.61134998, 0.61835511, 0.6396278 ]),\n",
       " 'split3_test_score': array([0.65223966, 0.64897231, 0.63483364, 0.67144528, 0.66830885,\n",
       "        0.65976392, 0.65810109, 0.65674443, 0.66731469, 0.67185735,\n",
       "        0.66891638, 0.65789785, 0.66878696, 0.65625279]),\n",
       " 'split4_test_score': array([0.35810128, 0.35429839, 0.36239276, 0.40293135, 0.39052338,\n",
       "        0.39076701, 0.376558  , 0.38617707, 0.38929686, 0.38015029,\n",
       "        0.37841042, 0.38192448, 0.38415196, 0.37441612]),\n",
       " 'mean_test_score': array([0.55863443, 0.55895352, 0.5617173 , 0.57151242, 0.56815326,\n",
       "        0.57181218, 0.5660541 , 0.57048787, 0.57511989, 0.58161142,\n",
       "        0.58044597, 0.56697483, 0.5751821 , 0.56933242]),\n",
       " 'std_test_score': array([0.10918843, 0.1108677 , 0.10656664, 0.09543928, 0.09871391,\n",
       "        0.09737004, 0.10192638, 0.0986283 , 0.10206443, 0.11027994,\n",
       "        0.11036797, 0.10070364, 0.10427217, 0.10598895]),\n",
       " 'rank_test_score': array([14, 13, 12,  6,  9,  5, 11,  7,  4,  1,  2, 10,  3,  8])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0            3.0         130.0       11.0  0.568208\n",
    "1            4.0         130.0       11.0  0.571646\n",
    "2            4.0         260.0       11.0  0.572041\n",
    "3            4.0         260.0       17.0  0.575256\n",
    "4            3.0         260.0       17.0  0.581006\n",
    "5            3.0         190.0       17.0  0.579441\n",
    "6            3.0         260.0       14.0  0.579117\n",
    "7            2.0         260.0       17.0  0.586584\n",
    "8            2.0         220.0       17.0  0.586569\n",
    "9            2.0         260.0       15.0  0.585127\n",
    "10           2.0         240.0       17.0  0.586714\n",
    "11           2.0         240.0       16.0  0.587155\n",
    "12           3.0         240.0       16.0  0.581932\n",
    "13           2.0         250.0       16.0  0.587126\n",
    "14           2.0         230.0       16.0  0.586972\n",
    "15           2.0         240.0       15.0  0.585551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T21:27:33.955099Z",
     "start_time": "2019-06-10T21:27:33.915097Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.410081</td>\n",
       "      <td>0.564371</td>\n",
       "      <td>0.256215</td>\n",
       "      <td>0.205643</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 130, 'max_...</td>\n",
       "      <td>0.640238</td>\n",
       "      <td>0.535233</td>\n",
       "      <td>0.648533</td>\n",
       "      <td>0.648520</td>\n",
       "      <td>0.368516</td>\n",
       "      <td>0.568208</td>\n",
       "      <td>0.108678</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.206218</td>\n",
       "      <td>1.046883</td>\n",
       "      <td>0.694637</td>\n",
       "      <td>0.451945</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 130, 'max_...</td>\n",
       "      <td>0.642258</td>\n",
       "      <td>0.542479</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.652713</td>\n",
       "      <td>0.382582</td>\n",
       "      <td>0.571646</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.779471</td>\n",
       "      <td>2.149982</td>\n",
       "      <td>0.944454</td>\n",
       "      <td>0.642650</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.640165</td>\n",
       "      <td>0.542508</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.655306</td>\n",
       "      <td>0.382932</td>\n",
       "      <td>0.572041</td>\n",
       "      <td>0.102694</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.363135</td>\n",
       "      <td>3.132739</td>\n",
       "      <td>1.152666</td>\n",
       "      <td>0.720452</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.655224</td>\n",
       "      <td>0.553209</td>\n",
       "      <td>0.595521</td>\n",
       "      <td>0.666836</td>\n",
       "      <td>0.405489</td>\n",
       "      <td>0.575256</td>\n",
       "      <td>0.094339</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.319076</td>\n",
       "      <td>2.690995</td>\n",
       "      <td>1.072861</td>\n",
       "      <td>0.631460</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.658834</td>\n",
       "      <td>0.558860</td>\n",
       "      <td>0.618489</td>\n",
       "      <td>0.672638</td>\n",
       "      <td>0.396209</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.100498</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.794446</td>\n",
       "      <td>1.947680</td>\n",
       "      <td>1.000457</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 190, 'max_...</td>\n",
       "      <td>0.658494</td>\n",
       "      <td>0.557957</td>\n",
       "      <td>0.613764</td>\n",
       "      <td>0.672873</td>\n",
       "      <td>0.394115</td>\n",
       "      <td>0.579441</td>\n",
       "      <td>0.100960</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.790129</td>\n",
       "      <td>2.237539</td>\n",
       "      <td>1.035058</td>\n",
       "      <td>0.646724</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.654948</td>\n",
       "      <td>0.549471</td>\n",
       "      <td>0.640972</td>\n",
       "      <td>0.661926</td>\n",
       "      <td>0.388270</td>\n",
       "      <td>0.579117</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.482013</td>\n",
       "      <td>2.532406</td>\n",
       "      <td>1.203167</td>\n",
       "      <td>0.702678</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.667912</td>\n",
       "      <td>0.552474</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0.676205</td>\n",
       "      <td>0.398187</td>\n",
       "      <td>0.586584</td>\n",
       "      <td>0.103886</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.311648</td>\n",
       "      <td>2.123982</td>\n",
       "      <td>0.989456</td>\n",
       "      <td>0.570010</td>\n",
       "      <td>2</td>\n",
       "      <td>220</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 220, 'max_...</td>\n",
       "      <td>0.667595</td>\n",
       "      <td>0.552820</td>\n",
       "      <td>0.636216</td>\n",
       "      <td>0.676780</td>\n",
       "      <td>0.399435</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.782526</td>\n",
       "      <td>1.909332</td>\n",
       "      <td>1.024857</td>\n",
       "      <td>0.605029</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.663775</td>\n",
       "      <td>0.554553</td>\n",
       "      <td>0.650008</td>\n",
       "      <td>0.668022</td>\n",
       "      <td>0.389275</td>\n",
       "      <td>0.585127</td>\n",
       "      <td>0.106357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.062897</td>\n",
       "      <td>2.358162</td>\n",
       "      <td>1.118363</td>\n",
       "      <td>0.696085</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 240, 'max_...</td>\n",
       "      <td>0.668035</td>\n",
       "      <td>0.552859</td>\n",
       "      <td>0.636320</td>\n",
       "      <td>0.677675</td>\n",
       "      <td>0.398678</td>\n",
       "      <td>0.586714</td>\n",
       "      <td>0.103780</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.116141</td>\n",
       "      <td>2.228857</td>\n",
       "      <td>1.066557</td>\n",
       "      <td>0.604481</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.669155</td>\n",
       "      <td>0.553692</td>\n",
       "      <td>0.648246</td>\n",
       "      <td>0.672126</td>\n",
       "      <td>0.392558</td>\n",
       "      <td>0.587155</td>\n",
       "      <td>0.106456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.078398</td>\n",
       "      <td>2.769038</td>\n",
       "      <td>1.013057</td>\n",
       "      <td>0.659980</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 240, 'max_...</td>\n",
       "      <td>0.662020</td>\n",
       "      <td>0.550759</td>\n",
       "      <td>0.626467</td>\n",
       "      <td>0.674055</td>\n",
       "      <td>0.396360</td>\n",
       "      <td>0.581932</td>\n",
       "      <td>0.102267</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.488364</td>\n",
       "      <td>2.254307</td>\n",
       "      <td>1.041558</td>\n",
       "      <td>0.658991</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 250, 'max_...</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.553838</td>\n",
       "      <td>0.647980</td>\n",
       "      <td>0.672126</td>\n",
       "      <td>0.392275</td>\n",
       "      <td>0.587126</td>\n",
       "      <td>0.106559</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.672617</td>\n",
       "      <td>2.353820</td>\n",
       "      <td>1.000656</td>\n",
       "      <td>0.623817</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 230, 'max_...</td>\n",
       "      <td>0.669344</td>\n",
       "      <td>0.553502</td>\n",
       "      <td>0.648449</td>\n",
       "      <td>0.672628</td>\n",
       "      <td>0.390938</td>\n",
       "      <td>0.586972</td>\n",
       "      <td>0.107192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.409309</td>\n",
       "      <td>2.074950</td>\n",
       "      <td>1.096463</td>\n",
       "      <td>0.683481</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 260, 'max_...</td>\n",
       "      <td>0.663631</td>\n",
       "      <td>0.554281</td>\n",
       "      <td>0.650274</td>\n",
       "      <td>0.668340</td>\n",
       "      <td>0.391230</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.105715</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.410081      0.564371         0.256215        0.205643   \n",
       "1        2.206218      1.046883         0.694637        0.451945   \n",
       "2        4.779471      2.149982         0.944454        0.642650   \n",
       "3        9.363135      3.132739         1.152666        0.720452   \n",
       "4        8.319076      2.690995         1.072861        0.631460   \n",
       "5        7.794446      1.947680         1.000457        0.685274   \n",
       "6        5.790129      2.237539         1.035058        0.646724   \n",
       "7        7.482013      2.532406         1.203167        0.702678   \n",
       "8        6.311648      2.123982         0.989456        0.570010   \n",
       "9        5.782526      1.909332         1.024857        0.605029   \n",
       "10       7.062897      2.358162         1.118363        0.696085   \n",
       "11       6.116141      2.228857         1.066557        0.604481   \n",
       "12       7.078398      2.769038         1.013057        0.659980   \n",
       "13       6.488364      2.254307         1.041558        0.658991   \n",
       "14       5.672617      2.353820         1.000656        0.623817   \n",
       "15       5.409309      2.074950         1.096463        0.683481   \n",
       "\n",
       "   param_max_features param_n_estimators param_max_depth  \\\n",
       "0                   3                130              11   \n",
       "1                   4                130              11   \n",
       "2                   4                260              11   \n",
       "3                   4                260              11   \n",
       "4                   3                260              17   \n",
       "5                   3                190              17   \n",
       "6                   4                260              17   \n",
       "7                   2                260              17   \n",
       "8                   2                220              17   \n",
       "9                   3                260              17   \n",
       "10                  2                240              17   \n",
       "11                  2                260              17   \n",
       "12                  3                240              16   \n",
       "13                  2                250              16   \n",
       "14                  2                230              16   \n",
       "15                  2                240              15   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_features': 3, 'n_estimators': 130, 'max_...           0.640238   \n",
       "1   {'max_features': 4, 'n_estimators': 130, 'max_...           0.642258   \n",
       "2   {'max_features': 4, 'n_estimators': 260, 'max_...           0.640165   \n",
       "3   {'max_features': 4, 'n_estimators': 260, 'max_...           0.655224   \n",
       "4   {'max_features': 3, 'n_estimators': 260, 'max_...           0.658834   \n",
       "5   {'max_features': 3, 'n_estimators': 190, 'max_...           0.658494   \n",
       "6   {'max_features': 4, 'n_estimators': 260, 'max_...           0.654948   \n",
       "7   {'max_features': 2, 'n_estimators': 260, 'max_...           0.667912   \n",
       "8   {'max_features': 2, 'n_estimators': 220, 'max_...           0.667595   \n",
       "9   {'max_features': 3, 'n_estimators': 260, 'max_...           0.663775   \n",
       "10  {'max_features': 2, 'n_estimators': 240, 'max_...           0.668035   \n",
       "11  {'max_features': 2, 'n_estimators': 260, 'max_...           0.669155   \n",
       "12  {'max_features': 3, 'n_estimators': 240, 'max_...           0.662020   \n",
       "13  {'max_features': 2, 'n_estimators': 250, 'max_...           0.669410   \n",
       "14  {'max_features': 2, 'n_estimators': 230, 'max_...           0.669344   \n",
       "15  {'max_features': 2, 'n_estimators': 260, 'max_...           0.663631   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.535233           0.648533           0.648520   \n",
       "1            0.542479           0.638197           0.652713   \n",
       "2            0.542508           0.639291           0.655306   \n",
       "3            0.553209           0.595521           0.666836   \n",
       "4            0.558860           0.618489           0.672638   \n",
       "5            0.557957           0.613764           0.672873   \n",
       "6            0.549471           0.640972           0.661926   \n",
       "7            0.552474           0.638144           0.676205   \n",
       "8            0.552820           0.636216           0.676780   \n",
       "9            0.554553           0.650008           0.668022   \n",
       "10           0.552859           0.636320           0.677675   \n",
       "11           0.553692           0.648246           0.672126   \n",
       "12           0.550759           0.626467           0.674055   \n",
       "13           0.553838           0.647980           0.672126   \n",
       "14           0.553502           0.648449           0.672628   \n",
       "15           0.554281           0.650274           0.668340   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.368516         0.568208        0.108678               16  \n",
       "1            0.382582         0.571646        0.102550               15  \n",
       "2            0.382932         0.572041        0.102694               14  \n",
       "3            0.405489         0.575256        0.094339               13  \n",
       "4            0.396209         0.581006        0.100498               10  \n",
       "5            0.394115         0.579441        0.100960               11  \n",
       "6            0.388270         0.579117        0.103668               12  \n",
       "7            0.398187         0.586584        0.103886                5  \n",
       "8            0.399435         0.586569        0.103273                6  \n",
       "9            0.389275         0.585127        0.106357                8  \n",
       "10           0.398678         0.586714        0.103780                4  \n",
       "11           0.392558         0.587155        0.106456                1  \n",
       "12           0.396360         0.581932        0.102267                9  \n",
       "13           0.392275         0.587126        0.106559                2  \n",
       "14           0.390938         0.586972        0.107192                3  \n",
       "15           0.391230         0.585551        0.105715                7  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(pattern_search.cv_results_)\n",
    "#df.param_max_depth = pattern_search.ResultDf.max_depth\n",
    "df\n",
    "#dict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKopt Baysian Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:41:22.878279Z",
     "start_time": "2019-06-10T23:37:43.461932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160, 4, 16]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 19.713969\n",
      "0.5804561876381765\n",
      "[230, 3, 9]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 13.592751\n",
      "0.5633404171586573\n",
      "[80, 2, 8]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.246977\n",
      "0.5338816384970145\n",
      "[130, 4, 11]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.448608\n",
      "0.5716457672950467\n",
      "[110, 4, 9]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 9.292519\n",
      "0.5672778425641961\n",
      "[170, 3, 17]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 23.282156\n",
      "0.5797454163949272\n",
      "[40, 4, 11]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 6.196290\n",
      "0.5646565383343194\n",
      "[210, 3, 13]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 17.315371\n",
      "0.5773590854644913\n",
      "[190, 3, 11]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 12.991142\n",
      "0.569253316186459\n",
      "[200, 2, 11]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 13.093239\n",
      "0.5654740284209414\n",
      "[130, 4, 5]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 8.062445\n",
      "0.5415908930624735\n",
      "[130, 4, 6]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 8.294449\n",
      "0.5489125300635678\n",
      "[130, 4, 15]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 14.680755\n",
      "0.5784964579497737\n",
      "[130, 4, 10]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 10.311504\n",
      "0.5711723583670343\n",
      "[130, 4, 12]\n",
      "Training data set shape: (100553, 17)\n",
      "Cross Validation Time: 11.829109\n",
      "0.5708607628560781\n"
     ]
    }
   ],
   "source": [
    "PercentToUse=100\n",
    "def objective(params):\n",
    "    print(params)\n",
    "    keys=['n_estimators','max_features','max_depth']\n",
    "    xc=dict(zip(keys,params))\n",
    "    Score,EV,_,_,R2=CrossEval(PercentToUse, xc)\n",
    "    print(R2)\n",
    "    return -R2\n",
    "\n",
    "from skopt import gp_minimize\n",
    "\n",
    "# Space=[[230,240,250],  #'n_estimators'\n",
    "#        [2,3], #'max_features'\n",
    "#        [16,17,30]] #'max_depth'\n",
    "\n",
    "Space=[[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260],\n",
    "       [2,3,4],\n",
    "       [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
    "\n",
    "#gp_minimize requires a minimum of 10 function calls\n",
    "r=gp_minimize(objective, Space, n_calls=15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKopt Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:41:43.768955Z",
     "start_time": "2019-06-10T23:41:43.763955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160, 4, 16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.5804561876381765"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r.x)\n",
    "r.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T23:41:47.898191Z",
     "start_time": "2019-06-10T23:41:47.892191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.58045619, -0.56334042, -0.53388164, -0.57164577, -0.56727784,\n",
       "       -0.57974542, -0.56465654, -0.57735909, -0.56925332, -0.56547403,\n",
       "       -0.54159089, -0.54891253, -0.57849646, -0.57117236, -0.57086076])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.func_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T22:20:26.604963Z",
     "start_time": "2019-06-08T22:20:26.547960Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-2cc7da021b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "from skopt.plots import plot_objective\n",
    "plot_objective(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn.feature_selection RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T18:25:59.169852Z",
     "start_time": "2019-05-17T18:24:13.465807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Measured Fit Time:  2.8331620693206787\n",
      " \n",
      " \n",
      "Model Parameters: \n",
      "{'bootstrap': False, 'criterion': 'mse', 'max_depth': 15, 'max_features': 2, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 250, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      " \n",
      " \n",
      "Feature ranking:\n",
      "1. feature 6 IsOpen (0.380287)\n",
      "2. feature 4 HasPromotions (0.155310)\n",
      "3. feature 2 Day of week (number) (0.104303)\n",
      "4. feature 13 StoreID (0.045440)\n",
      "5. feature 11 Region_GDP (0.043561)\n",
      "6. feature 14 StoreType (0.042415)\n",
      "7. feature 5 IsHoliday (0.039981)\n",
      "8. feature 8 NearestCompetitor (0.039229)\n",
      "9. feature 0 AssortmentType (0.034189)\n",
      "10. feature 10 Region_AreaKM2 (0.023997)\n",
      "11. feature 12 Region_PopulationK (0.022469)\n",
      "12. feature 9 Region (0.019379)\n",
      "13. feature 3 Day of year (0.013333)\n",
      "14. feature 1 Day of month (0.012330)\n",
      "15. feature 15 Week (0.011289)\n",
      "16. feature 7 Month (number) (0.009551)\n",
      "17. feature 16 Year (0.002939)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Optimal number of features : 17\n",
      "Cross Validation scores:\n",
      "[0.50902468 0.51332164 0.52919985 0.53358259 0.5450329  0.55599046\n",
      " 0.55423666 0.57229944 0.57475315 0.57465382 0.58177904 0.58092576\n",
      " 0.58548121]\n",
      "                 Feature  Importance  Rank\n",
      "0                 IsOpen    0.380287     1\n",
      "1          HasPromotions    0.155310     2\n",
      "2   Day of week (number)    0.104303     3\n",
      "3                StoreID    0.045440     4\n",
      "4             Region_GDP    0.043561     5\n",
      "5              StoreType    0.042415     6\n",
      "6              IsHoliday    0.039981     7\n",
      "7      NearestCompetitor    0.039229     8\n",
      "8         AssortmentType    0.034189     9\n",
      "9         Region_AreaKM2    0.023997    10\n",
      "10    Region_PopulationK    0.022469    11\n",
      "11                Region    0.019379    12\n",
      "12           Day of year    0.013333    13\n",
      "13          Day of month    0.012330    14\n",
      "14                  Week    0.011289    15\n",
      "15        Month (number)    0.009551    16\n",
      "16                  Year    0.002939    17\n",
      "(100553, 17)\n",
      "(100553, 17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 17\n",
      "Best features : Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n",
      "Original features : Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#forest = RandomForestRegressor(n_estimators=242, n_jobs=-1, random_state=0)\n",
    "start=time.time()\n",
    "forest = ExtraTreesRegressor(n_estimators=250, \n",
    "                             n_jobs=-1, \n",
    "                             max_depth = 15, \n",
    "                             max_features = 2,\n",
    "                             random_state=0)\n",
    "\n",
    "forest.fit(trainDataset_X, trainDataset_y)\n",
    "M_FitTime = time.time() - start\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Measured Fit Time: \", M_FitTime)\n",
    "\n",
    "UseTScv=True\n",
    "if UseTScv:\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    #start=time.time()\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    #scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=tscv, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )        \n",
    "else:\n",
    "    from sklearn.model_selection import KFold\n",
    "    #start=time.time()\n",
    "    kfolds = KFold(n_splits=5,shuffle=False,random_state=0)\n",
    "    #scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=kfolds, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )\n",
    "    \n",
    "#XValidTime = time.time() - start\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#print(\"Cross Validation Performance: \")\n",
    "#print(\"Cross Validation Time: %0.2f\" % (XValidTime))\n",
    "#EV=scores['test_explained_variance'].mean()\n",
    "#print(scores['test_explained_variance'])\n",
    "#print(\"EV: %0.2f\" % (EV))\n",
    "##MAE is less sensitive to outliers, The contant value that minimizes the MAE is the median of the target values\n",
    "#print(-1*scores['test_neg_mean_absolute_error'])\n",
    "#MAE=-1*scores['test_neg_mean_absolute_error'].mean()\n",
    "#print(\"MAE: %0.2f\" % (MAE))\n",
    "##MAE considers outliers, The contant value that minimizes the MSE is the mean of the target values\n",
    "##If you think your outliers are erros in the data use MAE, if you think the outliers are true datapoints use MSE.\n",
    "##It is easier to optmize MSE than RMSE because RMSE requires an adjustable learning rate.\n",
    "#print(-1*scores['test_neg_mean_squared_error'])\n",
    "#MSE=-1*scores['test_neg_mean_squared_error'].mean()\n",
    "#print(\"MSE: %0.2f\" % (MSE))\n",
    "#print(np.sqrt(-1*scores['test_neg_mean_squared_error']))\n",
    "#RMSE=np.sqrt(-1*scores['test_neg_mean_squared_error'].mean())\n",
    "#print(\"RMSE: %0.2f\" % (RMSE))\n",
    "##Optimizing R2 and optimizing for MSE is the same, since R2 = 1-(MSE/Constant)\n",
    "#print(\"XV R2 Actuals:\",scores['test_r2'])\n",
    "#R2=scores['test_r2'].mean()\n",
    "#print(\"Cross Validation R2: %0.2f\" % (R2))\n",
    "#print(\"XVR_fit_time Actuals: \", (scores['fit_time']))\n",
    "#XVR_FT=scores['fit_time'].mean()\n",
    "#print(\"XVR_fit_time: %0.2f\" % (XVR_FT))\n",
    "#print(\"score_time Actuals: \", (scores['score_time']))      \n",
    "#ST=scores['score_time'].mean()\n",
    "#print(\"score_time: %0.2f\" % (ST))\n",
    "Params=forest.get_params(deep=True)\n",
    "#print(\" \")\n",
    "#print(\" \")\n",
    "print(\"Model Parameters: \")\n",
    "print(Params)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "d=[]\n",
    "for f in range(trainDataset_X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], trainDataset_X.columns[indices[f]], importances[indices[f]]))\n",
    "    d.append({'Feature': trainDataset_X.columns[indices[f]]})\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "selector = RFECV(forest, step=1, cv=tscv, min_features_to_select=5,n_jobs=-1,verbose=0)\n",
    "selector = selector.fit(trainDataset_X, trainDataset_y)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)\n",
    "print(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "print(\"Cross Validation scores:\")\n",
    "print(selector.grid_scores_)\n",
    "\n",
    "trainDataset_XS=pd.DataFrame(trainDataset_X[trainDataset_X.columns[selector.support_]])\n",
    "#print(trainDataset_XS.head(3))\n",
    "\n",
    "FI=[]\n",
    "importancesS = selector.estimator_.feature_importances_\n",
    "indicesS = np.argsort(importancesS)[::-1]\n",
    "for f in range(trainDataset_XS.shape[1]):\n",
    "    #print(\"%d. feature %d %s (%f)\" % (f + 1, indicesS[f], trainDataset_XS.columns[indicesS[f]], importancesS[indicesS[f]]))\n",
    "    FI.append({'Rank':f+1, 'Feature':trainDataset_XS.columns[indicesS[f]], 'Importance':importancesS[indicesS[f]]})\n",
    "\t\n",
    "Feat_Imp = pd.DataFrame(FI)\n",
    "print(Feat_Imp)\n",
    "#print(flow_variables)\n",
    "print(trainDataset_X.shape)\n",
    "print(trainDataset_XS.shape)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(trainDataset_X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(trainDataset_X.shape[1]), trainDataset_X.columns[indices],rotation=90)\n",
    "plt.xlim([-1, trainDataset_X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Optimal number of features :', selector.n_features_)\n",
    "print('Best features :', trainDataset_X.columns[selector.support_])\n",
    "print('Original features :', trainDataset_X.columns)\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score \\n of number of selected features\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "plt.show()\n",
    "plt.savefig('C:\\\\Benchmarking\\\\FeatureImportance.png')\n",
    "output_table = trainDataset_XS.join(trainDataset_y, lsuffix='_X', rsuffix='_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection \n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:20:39.322423Z",
     "start_time": "2019-05-27T13:18:08.605803Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-208c08eb11f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeature_selection_univariate_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutual_info_regression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_selected_features_univariate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_selection_univariate_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataset_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainDataset_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reduced data set shape is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_selected_features_univariate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \"\"\"\n\u001b[0;32m    369\u001b[0m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[1;32m--> 370\u001b[1;33m                         copy, random_state)\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[1;32m--> 289\u001b[1;33m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[1;32m--> 289\u001b[1;33m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[1;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[1;34m(x, y, n_neighbors)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mnx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[1;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[0;32m    769\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind_neighbor\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m                 \u001b[0mneigh_ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind_neighbor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                     \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "feature_selection_univariate_model = SelectKBest(mutual_info_regression, k=4)\n",
    "X_selected_features_univariate = feature_selection_univariate_model.fit_transform(trainDataset_X,trainDataset_y)\n",
    "print(\"Reduced data set shape is \",X_selected_features_univariate.shape)\n",
    "\n",
    "mask = feature_selection_univariate_model.get_support() #list of booleans\n",
    "print(\"Selected features = \",data.feature_names[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "We now apply principal component analysis. Since we need to decide how many component to select and for this purpose we apply PCA and plot the explained variance ratio and the cumulative explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "full_pca_model = PCA()\n",
    "full_fitted_model = full_pca_model.fit(trainDataset_X)\n",
    "print(full_fitted_model.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(full_fitted_model.explained_variance_ratio_.cumsum(), '--o');\n",
    "plt.xticks(np.arange(0,12,1));\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can note, four components can actually explain most of the variance in the data so we apply PCA and select the first four components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_pca_model = PCA(n_components=4)\n",
    "fitted_model = feature_selection_pca_model.fit(trainDataset_X)\n",
    "\n",
    "X_selected_features_pca = fitted_model.transform(trainDataset_X)\n",
    "print(\"Explained Variance: %s\" % fitted_model.explained_variance_ratio_)\n",
    "print(\"Reduced data set shape is \", X_selected_features_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Search Matlab Method: (Worse results than Hooke-Jeeves)\n",
    "### Reference:\n",
    "https://www.mathworks.com/videos/global-optimization-with-matlab-products-81716.html (Time: 43:20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters Found (Hooke-Jeeves Method):\n",
    "n_estimators     7.000000\n",
    "max_features     4.000000\n",
    "max_depth       16.000000\n",
    "score            0.555353\n",
    "Name: 9, dtype: float64\n",
    "12           7.0           4.0       15.0  0.538425\n",
    "\n",
    "Best Parameters Found (MATLAB Method:)\n",
    "n_estimators    7.000000\n",
    "max_features    4.000000\n",
    "max_depth       8.000000\n",
    "score           0.553186\n",
    "Name: 15, dtype: float64\n",
    "23           7.0           4.0        7.0  0.530708\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:23:27.859307Z",
     "start_time": "2019-06-10T19:23:27.805304Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run This cell and then the \"#Execute Pattern Search:\" cell\n",
    "class PatternSearchCV(BaseSearchCV2):\n",
    "    _required_parameters = [\"estimator\", \"param_distributions\"]\n",
    "\n",
    "    def __init__(self, estimator, param_distributions, scoring=None, #n_iter=10,\n",
    "                 n_jobs=None, iid='warn', refit=True,\n",
    "                 cv='warn', verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 random_state=None, error_score='raise-deprecating',\n",
    "                 return_train_score=False):\n",
    "        self.param_distributions = param_distributions\n",
    "        #self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        super().__init__(\n",
    "            estimator=estimator, scoring=scoring,\n",
    "            n_jobs=n_jobs, iid=iid, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "        self.ResultDf = pd.DataFrame()\n",
    "\n",
    "#     param_dist={'n_estimators':[230,240,250],\n",
    "#            'max_features':[2,3],\n",
    "#            'max_depth':[16,17,30]}        \n",
    "        \n",
    "        class Dimension():\n",
    "            def __init__(self, value):\n",
    "                #If value is a Tuple, divide the interval into \"length\" equaly spaced intervals:\n",
    "                if isinstance(value,tuple):\n",
    "                   lower=value[0];upper=value[1];length=value[2]\n",
    "                   value=[lower + x*(upper-lower)/(length-1) for x in range(length)]\n",
    "                self.value=value\n",
    "                self.value.sort()\n",
    "                self.min=self.value[0]\n",
    "                self.max=self.value[-1]\n",
    "                self.midptidx=int((len(self.value)/2)-0.5)\n",
    "                self.midpoint=self.value[self.midptidx]\n",
    "                self.Delta=(len(value)-1)-self.midptidx\n",
    "                self.BestValue=self.midpoint\n",
    "                self.CurrIndex=self.midptidx\n",
    "                self.BestIndex=self.midptidx\n",
    "        \n",
    "        self.Space={}\n",
    "        for Dkey, Dval in param_dist.items():\n",
    "            self.Space[Dkey]=Dimension(Dval)\n",
    "            print(Dkey,\":\",Dval) \n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Search best parameters using Pattern Search Method\"\"\"\n",
    "        alfa=2;Episilon=0.001 ;k=0\n",
    "        Ndimensions=len(self.Space); \n",
    "\n",
    "        xc={}; xd={}; xb={}\n",
    "        #builds the first exploratory point by collecting the midpoint of each dimension:\n",
    "        for Dkey, Dval in self.Space.items():\n",
    "            xc[Dkey]=Dval.midpoint   \n",
    "\n",
    "        for CurDim in range(0,Ndimensions): #divide Delta by 2\n",
    "            #print(\"Dividing delta by 2:\")\n",
    "            list(self.Space.values())[CurDim].Delta=int(0.5+list(self.Space.values())[CurDim].Delta/alfa)\n",
    "\n",
    "        DeltaVector=[]\n",
    "        for CurDim in range(0,Ndimensions):\n",
    "            DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "        print(\" \")\n",
    "        print(\"Current Delta values for each dimension: \", DeltaVector)\n",
    "\n",
    "        #Evaluate the first point as the midpoint of the search space:\n",
    "        BestScore = evaluate_candidates([xc])['mean_test_score'][-1]\n",
    "        print(\" \")\n",
    "        print(xc)\n",
    "\n",
    "        cols=list(xc.keys())\n",
    "        cols.append('score')\n",
    "        df=pd.DataFrame(columns=cols)\n",
    "        xd=xc.copy()\n",
    "        xd.update({'score':BestScore})\n",
    "        df=df.append(xd, ignore_index=True)\n",
    "        print(df)\n",
    "\n",
    "        BestIdx=0; InitialExploration=0\n",
    "\n",
    "\n",
    "        # i=exploratory moves iterations; k=Overall Iterations\n",
    "        i=0; Continue=0\n",
    "\n",
    "        while Continue<3:\n",
    "            #Exploratory Search:\n",
    "            while i < Ndimensions:\n",
    "                k+=1\n",
    "                #print(\"Iteration k:\",k)\n",
    "                print(\"Dimension: \",i+1)\n",
    "                for Direction in [1,-1]:\n",
    "                    xn={}; xd={}\n",
    "                    for CurDim in range(0,Ndimensions): #Build the vextor xn:\n",
    "                        if i == CurDim:\n",
    "                            NewIndex=list(self.Space.values())[CurDim].CurrIndex + Direction*list(self.Space.values())[CurDim].Delta\n",
    "                            if NewIndex>len(list(self.Space.values())[CurDim].value)-1: NewIndex=len(list(self.Space.values())[CurDim].value)-1\n",
    "                            if NewIndex<0: NewIndex=0\n",
    "                            xn[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].value[NewIndex]\n",
    "                        else:\n",
    "                            CurrInd=list(self.Space.values())[CurDim].CurrIndex\n",
    "                            if CurrInd>len(list(self.Space.values())[CurDim].value)-1: CurrInd=len(list(self.Space.values())[CurDim].value)-1\n",
    "                            if CurrInd<0: CurrInd =0\n",
    "                            xn[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].value[CurrInd]\n",
    "                    if list(xn.values()) not in df.drop(['score'], axis=1).values.tolist():\n",
    "                        print(Direction, xn)            \n",
    "                        CurrScore = evaluate_candidates([xn])['mean_test_score'][-1]\n",
    "                        #cols=list(xn.keys())\n",
    "                        #cols.append('score')\n",
    "                        xd=xn.copy()\n",
    "                        xd.update({'score':CurrScore})\n",
    "                        df=df.append(xd, ignore_index=True)\n",
    "                        print(df)\n",
    "                        #print(CurrScore)\n",
    "                        if CurrScore > BestScore: \n",
    "                            BestScore=CurrScore\n",
    "                            list(self.Space.values())[i].BestValue=list(self.Space.values())[i].value[NewIndex]\n",
    "                            list(self.Space.values())[i].BestIndex=NewIndex\n",
    "                            xb=xn.copy()\n",
    "                            BestIdx=k-1\n",
    "                            #break\n",
    "                #list(self.Space.values())[i].CurrIndex=list(self.Space.values())[i].BestIndex \n",
    "                i+=1\n",
    "            xd={}    \n",
    "            NotEqual=False\n",
    "            for Dkey, Dval in self.Space.items():\n",
    "                #print(Dval.CurrIndex,Dval.BestIndex)\n",
    "                if Dval.CurrIndex != Dval.BestIndex: NotEqual=True\n",
    "            print(\" \");print(\" \");\n",
    "            #print(\"NotEqual =\",NotEqual)\n",
    "            DeltaVector=[]\n",
    "            if NotEqual:\n",
    "                for CurDim in range(0,Ndimensions): #update Current index to Best Point:\n",
    "                    list(self.Space.values())[CurDim].CurrIndex=list(self.Space.values())[CurDim].BestIndex\n",
    "                    #xd[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].BestValue\n",
    "                    #BestIndex=list(self.Space.values())[CurDim].BestIndex\n",
    "                    #xn[list(self.Space.keys())[CurDim]]=list(self.Space.values())[CurDim].value[BestIndex]\n",
    "                #print(\"xn: \",xn)\n",
    "                #print(\"xd:\", xd)\n",
    "                print(\"Best vector so far (xb):\",xb) \n",
    "                #print(df.loc[df['score'].idxmax()])\n",
    "                #Multiply delta by 2\n",
    "                print(\"multiplying delta by 2:\")\n",
    "                for CurDim in range(0,Ndimensions):\n",
    "                    list(self.Space.values())[CurDim].Delta=int(0.5+list(self.Space.values())[CurDim].Delta*alfa)\n",
    "                    DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "            else:\n",
    "                print(\"Dividing delta by 2:\")\n",
    "                for CurDim in range(0,Ndimensions): #Stay in current point and divide Delta by 2\n",
    "                    list(self.Space.values())[CurDim].Delta=int(0.5+list(self.Space.values())[CurDim].Delta/alfa)\n",
    "                    DeltaVector.append(list(self.Space.values())[CurDim].Delta)\n",
    "\n",
    "            print(\"Current Delta values for each dimension: \",DeltaVector)\n",
    "            i=0 \n",
    "            if DeltaVector==list(np.ones(3)): Continue+=1\n",
    "\n",
    "        print(\" \");print(\" \")\n",
    "        print(\"Best Parameters Found:\")\n",
    "        print(df.loc[df['score'].idxmax()])\n",
    "        print(\" \");print(\" \")\n",
    "        self.ResultDf=df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T15:02:44.757032Z",
     "start_time": "2019-04-27T15:02:44.740031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5\n",
      "0.16\n",
      "0.14\n",
      "0.13\n"
     ]
    }
   ],
   "source": [
    "LearningRate = [0.14, 0.15, 0.16, 0.13, 0.13]\n",
    "EvalMetric = ['RMSE','R2']\n",
    "max_depth= [4,5,7,8]\n",
    "print(type(LearningRate))\n",
    "print(len(LearningRate))\n",
    "print(LearningRate[int((len(LearningRate)/2)-0.5)])\n",
    "print(LearningRate[0])\n",
    "print(LearningRate[len(LearningRate)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T13:22:45.708806Z",
     "start_time": "2019-05-14T13:22:45.688805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'EvalMetric': 'R2', 'LR': 0.1433033736034484, 'Max_depth': 4}\n",
      "R2\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# Create the domain space\n",
    "#LearningRate = hp.uniform('LearningRate', 0.14, 0.16)\n",
    "#EvalMetric = hp.choice('EvalMetric',['RMSE','R2','MAE'])\n",
    "#max_depth=hp.choice('max_depth', [4,5])\n",
    "#print(type(EvalMetric))\n",
    "space={'LR': hp.uniform('LearningRate', 0.14, 0.16),\n",
    "       'EvalMetric': hp.choice('EvalMetric',['RMSE','R2','MAE']),\n",
    "       'Max_depth': hp.choice('max_depth', [4,5])\n",
    "      }\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "samples=[]\n",
    "print(type(samples))\n",
    "for _ in range(5):\n",
    "    samples.append(sample(space))\n",
    "print(samples[0])\n",
    "print(samples[0]['EvalMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:34:53.578712Z",
     "start_time": "2019-04-25T21:34:53.568712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 4}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={}\n",
    "?a\n",
    "a['RMSE']=4\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Feature importances and Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns:\n",
      "Index(['StoreType', 'AssortmentType'], dtype='object')\n",
      " \n",
      " \n",
      "Head of Training Data:\n",
      "   StoreID  IsHoliday  IsOpen  HasPromotions  StoreType  AssortmentType  \\\n",
      "0     1000          0       1              0          0               0   \n",
      "1     1000          0       1              0          0               0   \n",
      "2     1000          0       1              0          0               0   \n",
      "\n",
      "   NearestCompetitor  Region  NumberOfSales  Region_AreaKM2  Region_GDP  \\\n",
      "0                326       7           5676            9643       17130   \n",
      "1                326       7           8111            9643       17130   \n",
      "2                326       7           8300            9643       17130   \n",
      "\n",
      "   Region_PopulationK  Year  Month (number)  Week  Day of year  Day of month  \\\n",
      "0                2770  2016               3    10           61             1   \n",
      "1                2770  2016               3    10           62             2   \n",
      "2                2770  2016               3    10           64             4   \n",
      "\n",
      "   Day of week (number)  \n",
      "0                     3  \n",
      "1                     4  \n",
      "2                     6  \n",
      " \n",
      " \n",
      "Train Data Type Descriptions:\n",
      "StoreID                 int32\n",
      "IsHoliday               int32\n",
      "IsOpen                  int32\n",
      "HasPromotions           int32\n",
      "StoreType                int8\n",
      "AssortmentType           int8\n",
      "NearestCompetitor       int32\n",
      "Region                  int32\n",
      "NumberOfSales           int32\n",
      "Region_AreaKM2          int32\n",
      "Region_GDP              int32\n",
      "Region_PopulationK      int32\n",
      "Year                    int32\n",
      "Month (number)          int32\n",
      "Week                    int32\n",
      "Day of year             int32\n",
      "Day of month            int32\n",
      "Day of week (number)    int32\n",
      "dtype: object\n",
      " \n",
      " \n",
      "Feature Columns:\n",
      "Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Measured Fit Time:  1.0066440105438232\n",
      "Using Time Series Cross Validation\n",
      " \n",
      " \n",
      "Cross Validation Performance: \n",
      "Cross Validation Time: 8.94\n",
      "[0.65366408 0.50842293 0.47459996 0.61972558 0.39699894]\n",
      "EV: 0.53\n",
      "[1049.49583483 1371.75359231 1321.84140112 1028.53560687 1305.02858933]\n",
      "MAE: 1215.33\n",
      "[2457903.34035326 4386336.06559434 3677100.90866691 2740695.37281478\n",
      " 5999530.01001014]\n",
      "MSE: 3852313.14\n",
      "[1567.77018097 2094.35815122 1917.57683253 1655.50456744 2449.3938046 ]\n",
      "RMSE: 1962.73\n",
      "XV R2 Actuals: [0.59961468 0.50834681 0.47195162 0.61962855 0.39681197]\n",
      "Cross Validation R2: 0.52\n",
      "XVR_fit_time Actuals:  [1.7638638  0.40660071 0.53040123 0.73700309 0.96720171]\n",
      "XVR_fit_time: 0.88\n",
      "score_time Actuals:  [0.45340085 0.43680072 0.45240045 0.45240092 0.43780088]\n",
      "score_time: 0.45\n",
      " \n",
      " \n",
      "Converting Validation Categorical Columns to Numbers:\n",
      " \n",
      " \n",
      "Head of Validation Data:\n",
      "   StoreID  IsHoliday  IsOpen  HasPromotions  StoreType  AssortmentType  \\\n",
      "0     1145          0       1              0          0               1   \n",
      "1     1145          0       1              0          0               1   \n",
      "2     1145          0       1              0          0               1   \n",
      "\n",
      "   NearestCompetitor  Region  NumberOfSales  Region_AreaKM2  Region_GDP  \\\n",
      "0                838      10           5605            7215       11849   \n",
      "1                838      10           6635            7215       11849   \n",
      "2                838      10           5981            7215       11849   \n",
      "\n",
      "   Region_PopulationK  Year  Month (number)  Week  Day of year  Day of month  \\\n",
      "0                1293  2016               3    10           61             1   \n",
      "1                1293  2016               3    10           62             2   \n",
      "2                1293  2016               3    10           64             4   \n",
      "\n",
      "   Day of week (number)  \n",
      "0                     3  \n",
      "1                     4  \n",
      "2                     6  \n",
      " \n",
      "Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n",
      " \n",
      " \n",
      "Prediction Time:  0.10920000076293945\n",
      " \n",
      "Validation Performance with ~20.000 records:\n",
      "Validation Set Explained Variance (EV): 0.60\n",
      "MAE: 1109.07\n",
      "MSE: 2394670.59\n",
      "RMSE: 1547.47\n",
      "Validation Set R2: 0.60\n",
      " \n",
      " \n",
      "Feature Importances:\n",
      "1. feature 6 IsOpen (0.466111)\n",
      "2. feature 13 StoreID (0.081406)\n",
      "3. feature 4 HasPromotions (0.070828)\n",
      "4. feature 8 NearestCompetitor (0.066025)\n",
      "5. feature 0 AssortmentType (0.051350)\n",
      "6. feature 2 Day of week (number) (0.046155)\n",
      "7. feature 11 Region_GDP (0.045231)\n",
      "8. feature 14 StoreType (0.027476)\n",
      "9. feature 12 Region_PopulationK (0.024956)\n",
      "10. feature 9 Region (0.021080)\n",
      "11. feature 1 Day of month (0.020623)\n",
      "12. feature 10 Region_AreaKM2 (0.019297)\n",
      "13. feature 3 Day of year (0.017966)\n",
      "14. feature 15 Week (0.016538)\n",
      "15. feature 7 Month (number) (0.014597)\n",
      "16. feature 16 Year (0.008076)\n",
      "17. feature 5 IsHoliday (0.002285)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Model Parameters:\n",
      "Win\n",
      "7\n",
      "3.6.7\n",
      "sklearn\n",
      "0.20.2\n",
      "['Win', '7', 'Python', '3.6.7', 'sklearn', '0.20.2', 'ExtraTreesRegressor', 1.0066440105438232, 0.8810141086578369, 0.44656076431274416, 8.939087629318237, 0.5306822996170675, 1215.3310048931853, 3852313.1394878863, 1962.731041046604, 0.5192707252591598, 0.10920000076293945, 0.6028330361805241, 1109.069321244793, 2394670.5888502817, 1547.4723224827906, 0.6003824226912086, {'bootstrap': False, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}, [{'1. feat: 6 IsOpen (0.466111)'}, {'2. feat: 13 StoreID (0.081406)'}, {'3. feat: 4 HasPromotions (0.070828)'}, {'4. feat: 8 NearestCompetitor (0.066025)'}, {'5. feat: 0 AssortmentType (0.051350)'}, {'6. feat: 2 Day of week (number) (0.046155)'}, {'7. feat: 11 Region_GDP (0.045231)'}, {'8. feat: 14 StoreType (0.027476)'}, {'9. feat: 12 Region_PopulationK (0.024956)'}, {'10. feat: 9 Region (0.021080)'}, {'11. feat: 1 Day of month (0.020623)'}, {'12. feat: 10 Region_AreaKM2 (0.019297)'}, {'13. feat: 3 Day of year (0.017966)'}, {'14. feat: 15 Week (0.016538)'}, {'15. feat: 7 Month (number) (0.014597)'}, {'16. feat: 16 Year (0.008076)'}, {'17. feat: 5 IsHoliday (0.002285)'}], StoreID                 int32\n",
      "IsHoliday               int32\n",
      "IsOpen                  int32\n",
      "HasPromotions           int32\n",
      "StoreType                int8\n",
      "AssortmentType           int8\n",
      "NearestCompetitor       int32\n",
      "Region                  int32\n",
      "NumberOfSales           int32\n",
      "Region_AreaKM2          int32\n",
      "Region_GDP              int32\n",
      "Region_PopulationK      int32\n",
      "Year                    int32\n",
      "Month (number)          int32\n",
      "Week                    int32\n",
      "Day of year             int32\n",
      "Day of month            int32\n",
      "Day of week (number)    int32\n",
      "dtype: object, 'Default Settings, TS CV, only 1 win. open']\n",
      "***Process Completed***\n"
     ]
    }
   ],
   "source": [
    "#Calculate Feature importances and Graph:\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Feature Importances:\")\n",
    "global d\n",
    "d=[]\n",
    "for f in range(trainDataset_X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], trainDataset_X.columns[indices[f]], importances[indices[f]]))\n",
    "    d.append({\"%d. feat: %d %s (%f)\" % (f + 1, indices[f], trainDataset_X.columns[indices[f]], importances[indices[f]])})\n",
    "\n",
    "Feat_Imp = pd.DataFrame(d)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(trainDataset_X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(trainDataset_X.shape[1]), trainDataset_X.columns[indices],rotation=90)\n",
    "plt.xlim([-1, trainDataset_X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "print(\" \")\n",
    "print(\"Model Parameters:\")\n",
    "Params\n",
    "\n",
    "\n",
    "#InsertHeader()\n",
    "InsertValues()\n",
    "print('***Process Completed***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T20:53:42.351221Z",
     "start_time": "2019-04-25T20:53:41.890199Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns:\n",
      "Index(['StoreType', 'AssortmentType'], dtype='object')\n",
      "Feature Columns:\n",
      "Index(['AssortmentType', 'Day of month', 'Day of week (number)', 'Day of year',\n",
      "       'HasPromotions', 'IsHoliday', 'IsOpen', 'Month (number)',\n",
      "       'NearestCompetitor', 'Region', 'Region_AreaKM2', 'Region_GDP',\n",
      "       'Region_PopulationK', 'StoreID', 'StoreType', 'Week', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Load Train Set:\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import csv\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "trainBench = pd.read_csv(\"c:/Benchmarking/trainBench.csv\")\n",
    "#testBench = pd.read_csv(\"c:/Benchmarking/testBench.csv\")\n",
    "\n",
    "trainBench = trainBench.drop(\"ID\", axis=1)\n",
    "\n",
    "cat_columns = trainBench.select_dtypes(['object']).columns\n",
    "print(\"Categorical Columns:\")\n",
    "print(cat_columns)\n",
    "trainBench[cat_columns] = trainBench[cat_columns].astype('category')\n",
    "cat_columns = trainBench.select_dtypes(['category']).columns\n",
    "trainBench[cat_columns] = trainBench[cat_columns].apply(lambda x: x.cat.codes)\n",
    "Int64columns = trainBench.select_dtypes(['int64']).columns\n",
    "#Int64columns\n",
    "trainBench[Int64columns] = trainBench[Int64columns].astype(np.int32)\n",
    "#trainBench.info()\n",
    "mask = trainBench.columns.difference(['NumberOfSales'])\n",
    "trainDataset_X = trainBench[mask]\n",
    "print(\"Feature Columns:\")\n",
    "print(mask)\n",
    "trainDataset_y = trainBench['NumberOfSales']\n",
    "del trainBench\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#Load Validation Set:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "validBench = pd.read_csv(\"c:/Benchmarking/validBench.csv\")\n",
    "validBench = validBench.drop(\"ID\", axis=1)\n",
    "#Int64columns = validBench.select_dtypes(['int64']).columns\n",
    "#Int64columns\n",
    "validBench[Int64columns] = validBench[Int64columns].astype(np.int32)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Converting Validation Categorical Columns to Numbers:\")\n",
    "cat_columns\n",
    "validBench[cat_columns] = validBench[cat_columns].astype('category')\n",
    "cat_columns = validBench.select_dtypes(['category']).columns\n",
    "validBench[cat_columns] = validBench[cat_columns].apply(lambda x: x.cat.codes)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Head of Validation Data:\")\n",
    "print(validBench.head(3))\n",
    "print(\" \")\n",
    "print(mask)\n",
    "validBench_X = validBench[mask]\n",
    "validBench_y = validBench['NumberOfSales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
      "TRAIN: [    0     1     2 ... 16760 16761 16762] TEST: [16763 16764 16765 ... 33518 33519 33520]\n",
      "TRAIN: [    0     1     2 ... 33518 33519 33520] TEST: [33521 33522 33523 ... 50276 50277 50278]\n",
      "TRAIN: [    0     1     2 ... 50276 50277 50278] TEST: [50279 50280 50281 ... 67034 67035 67036]\n",
      "TRAIN: [    0     1     2 ... 67034 67035 67036] TEST: [67037 67038 67039 ... 83792 83793 83794]\n",
      "TRAIN: [    0     1     2 ... 83792 83793 83794] TEST: [ 83795  83796  83797 ... 100550 100551 100552]\n"
     ]
    }
   ],
   "source": [
    "#Testing Time series cross validation:\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(tscv)\n",
    "#scores = cross_validate(forest, trainDataset_X, trainDataset_y, cv=kfolds, scoring=('r2','explained_variance','neg_mean_absolute_error','neg_mean_squared_error') )\n",
    "\n",
    "X = trainDataset_X\n",
    "y = trainDataset_y\n",
    " \n",
    "for train_index, test_index in tscv.split(y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.619px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 180.89234399999998,
   "position": {
    "height": "39.9957px",
    "left": "725.857px",
    "right": "20px",
    "top": "-6.01131px",
    "width": "480.515px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
